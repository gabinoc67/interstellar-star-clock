<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Relational Metrics Kit — Mini Theta Simulation + Sentinel Casanova Computer</title>
<style>
  :root{
    --bg:#0b1222;
    --panel:#121a33;
    --ink:#edf2ff;
    --muted:#a9b7e3;
    --accent:#8fb4ff;
    --good:#7bffb1;
    --warn:#ffd37a;
    --bad:#ff8c8c;
    --grid:#1b2550;
  }
  *{box-sizing:border-box}
  body{
    margin:0;
    background:var(--bg);
    color:var(--ink);
    font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;
  }
  .wrap{
    max-width:1100px;
    margin:0 auto;
    padding:16px;
  }
  h1{
    margin:4px 0 8px;
    font-size:1.6rem;
  }
  h2{
    margin:12px 0 4px;
    font-size:1.2rem;
    color:var(--accent);
  }
  h3{
    margin:4px 0 4px;
    font-size:1rem;
  }
  .panel{
    background:var(--panel);
    border-radius:10px;
    padding:12px 14px;
    box-shadow:0 0 0 1px rgba(0,0,0,.4);
    margin-bottom:16px;
  }
  .controls{
    display:flex;
    flex-wrap:wrap;
    gap:8px;
    align-items:center;
    font-size:.9rem;
  }
  button{
    border:none;
    border-radius:999px;
    padding:6px 14px;
    background:var(--accent);
    color:#020617;
    font-weight:600;
    cursor:pointer;
  }
  button:hover{
    filter:brightness(1.1);
  }
  canvas{
    width:100%;
    max-width:100%;
    border-radius:8px;
    background:#050816;
    display:block;
  }
  .legend{
    display:flex;
    flex-wrap:wrap;
    gap:10px;
    font-size:.8rem;
    color:var(--muted);
    margin-top:6px;
  }
  .pill{
    display:inline-flex;
    align-items:center;
    gap:4px;
    padding:2px 8px;
    border-radius:999px;
    background:#0d1733;
  }
  .dot{
    width:8px;
    height:8px;
    border-radius:50%;
    background:var(--accent);
  }
  .dot.theta{background:var(--good);}
  .dot.emerge{background:var(--bad);}
  .summary{
    font-size:.88rem;
    color:var(--muted);
  }
  .summary.small{
    font-size:.78rem;
  }
  table{
    width:100%;
    border-collapse:collapse;
    font-size:.78rem;
    margin-top:8px;
  }
  th,td{
    padding:4px 6px;
    text-align:right;
    border-bottom:1px solid rgba(255,255,255,.04);
  }
  th{
    text-align:center;
    color:var(--muted);
    background:#0d1733;
    position:sticky;
    top:0;
    z-index:1;
  }
  td.turn{
    text-align:center;
    color:var(--accent);
  }
  tr.emerge-row{
    background:rgba(255,255,160,0.18);
    animation: blinkRow 1s infinite alternate;
  }
  .scroll{
    max-height:260px;
    overflow:auto;
    border-radius:8px;
    border:1px solid #141b33;
  }
  code{
    background:#020617;
    padding:2px 4px;
    border-radius:4px;
    font-size:.8rem;
  }

  /* Consciousness / Subconscious layout */
  .layers-grid{
    display:flex;
    flex-wrap:wrap;
    gap:10px;
    margin-top:8px;
  }
  .layer-card{
    flex:1 1 230px;
    background:#0d1733;
    border-radius:8px;
    padding:8px 10px;
  }
  .status-line{
    font-size:.85rem;
    margin:4px 0;
  }
  .status-line span{
    color:var(--good);
  }
  .scroll.mini{
    max-height:120px;
    overflow:auto;
    margin-top:6px;
    font-size:.78rem;
    background:#020617;
    border-radius:6px;
    padding:6px;
    border:1px solid #141b33;
  }

  @keyframes blinkRow{
    from { background:rgba(255,255,160,0.18); }
    to   { background:rgba(255,255,0,0.55); }
  }

  @media print{
    body{
      background:#ffffff;
    }
    .panel{
      box-shadow:none;
      border-radius:0;
    }
    button{
      display:none;
    }
    tr.emerge-row{
      animation:none;
      background:#fff6a0 !important;
    }
  }

  .audio-meta,
  .text-meta{
    font-size:.78rem;
    color:var(--muted);
    margin-top:4px;
  }

  textarea{
    width:100%;
    min-height:140px;
    resize:vertical;
    border-radius:8px;
    border:1px solid #141b33;
    padding:8px;
    background:#020617;
    color:var(--ink);
    font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;
    font-size:.86rem;
  }
</style>
</head>
<body>
<div class="wrap">
  <div class="panel">
    <h1>Relational Metrics Kit — Mini Theta Simulation</h1>
    <p class="summary">
      This page simulates a simplified version of the <strong>Relational Metrics Kit (RMK)</strong> order
      parameter Θ over a 40-turn interaction, and compares it with an analogous Θ for the
      <strong>Sentinel Casanova Computer</strong> modeled as a qubit-based system. These simulations do
      <em>not</em> detect consciousness. They show how interaction patterns and quantum-coherence patterns
      change over time. Peaks in Θ are highlighted as bright, blinking “emergence” events.
    </p>
    <div class="controls">
      <button id="runBtn">Run New Simulation (Both)</button>
      <button id="resetBtn">Clear / Reset Simulation</button>
      <button id="printBtn">Print All</button>
      <button id="downloadRMKBtn">Download RMK Metrics (CSV)</button>
      <button id="downloadSentinelBtn">Download Sentinel Metrics (CSV)</button>
      <button id="downloadPNG_RMK">Download RMK Theta PNG</button>
      <button id="downloadPNG_Sentinel">Download Sentinel Theta PNG</button>
      <span>Turns: <strong>40</strong> &middot; Window for baseline: <strong>8</strong> turns</span>
    </div>
  </div>

  <!-- AUDIO → 27 EMOTIONS → RMK/SENTINEL -->
  <div class="panel">
    <h2>Conversation Audio (WAV) → 27 Emotions → RMK &amp; Sentinel</h2>
    <p class="summary small">
      This panel uses a <strong>toy model</strong> to map a WAV conversation into a 40-step bit stream (0/1) and
      <strong>27 emotion channels</strong>:
      admiration, adoration, aesthetic appreciation, amusement, anger, anxiety, awe, awkwardness, boredom, calmness,
      confusion, craving, disgust, empathic pain, entrancement, envy, excitement, fear, horror, interest, joy,
      nostalgia, romance, sadness, satisfaction, sexual desire, and surprise.
      It is a simulation for your RMK / Sentinel architecture, not a clinical analyzer.
    </p>
    <div class="controls">
      <button id="audioUploadBtn">1. Upload WAV Conversation</button>
      <button id="audioAnalyzeBtn">2. Analyze Tone → Bits + 27 Emotions</button>
      <button id="audioExportBtn">3. Download Audio Analysis (CSV)</button>
      <button id="audioLoadBtn">4. Upload Audio Analysis (CSV)</button>
      <button id="audioMapBtn">5. Map Audio to RMK &amp; Sentinel</button>
      <button id="audioClearBtn">Clear Audio &amp; Results</button>
      <input type="file" id="audioFileInput" accept=".wav,audio/wav" style="display:none" />
      <input type="file" id="audioAnalysisFileInput" accept=".csv,text/csv" style="display:none" />
    </div>
    <p class="audio-meta" id="audioStatus">
      No audio uploaded yet.
    </p>
    <div class="scroll mini" id="audioBitsBox">
      <!-- 0/1 pattern and 27-emotion snapshot for audio appear here -->
    </div>
  </div>

  <!-- TEXT → 27 EMOTIONS → RMK/SENTINEL -->
  <div class="panel">
    <h2>Paragraph (≥ 500 words) → 27 Emotions → RMK &amp; Sentinel</h2>
    <p class="summary small">
      Paste or type a paragraph (recommended: <strong>500+ words</strong>). The simulator will scan the text,
      assign relative values to the same 27 emotions, convert the pattern into a 40-step bit stream, and then map into
      RMK and Sentinel Θ timelines. This is a keyword + noise model for experimentation, not a real diagnostic tool.
    </p>
    <textarea id="textParagraph" placeholder="Type or paste at least 500 words here..."></textarea>
    <div class="controls" style="margin-top:6px;">
      <button id="textAnalyzeBtn">1. Analyze Paragraph → Bits + 27 Emotions</button>
      <button id="textExportBtn">2. Download Text Analysis (CSV)</button>
      <button id="textLoadBtn">3. Upload Text Analysis (CSV)</button>
      <button id="textMapBtn">4. Map Text to RMK &amp; Sentinel</button>
      <button id="textClearBtn">Clear Text &amp; Results</button>
      <input type="file" id="textAnalysisFileInput" accept=".csv,text/csv" style="display:none" />
    </div>
    <p class="text-meta" id="textStatus">
      No paragraph analyzed yet.
    </p>
    <div class="scroll mini" id="textBitsBox">
      <!-- 0/1 pattern and 27-emotion snapshot for text appear here -->
    </div>
  </div>

  <!-- RMK PANEL -->
  <div class="panel">
    <h2>RMK: Theta Timeline</h2>
    <canvas id="thetaCanvasRMK" width="1000" height="260"></canvas>
    <div class="legend">
      <span class="pill"><span class="dot theta"></span> Θ (order parameter)</span>
      <span class="pill"><span class="dot emerge"></span> Emergence peak (blinking)</span>
    </div>
  </div>

  <div class="panel">
    <h2>RMK: Turn-by-Turn Metrics</h2>
    <div class="scroll">
      <table id="metricsTableRMK">
        <thead>
          <tr>
            <th>t</th>
            <th>Hₜ</th>
            <th>Φₜ</th>
            <th>MIₜ</th>
            <th>Δₜ</th>
            <th>Θₜ</th>
            <th>z(Θ)</th>
            <th>Emergence?</th>
            <th>Layer Tag</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </div>

  <!-- CONSCIOUSNESS / SUBCONSCIOUS LAYERS -->
  <div class="panel">
    <h2>RMK — Consciousness &amp; Subconscious Layers</h2>
    <p class="summary">
      Here RMK is split into two “intelligence layers”: a <strong>Subconscious Engine</strong> (automatic survival math:
      movement checks, shutdown, protection) and a <strong>Conscious Captain</strong> (self-awareness math: reporting,
      choosing, interpreting survival). The meters below are derived from the current Θ timeline.
    </p>
    <div class="layers-grid">
      <div class="layer-card">
        <h3>Subconscious Engine (Automatic Layer)</h3>
        <p class="summary small">
          Handles movement checks, damage limits, survival reflexes — like a heart or sensor system that shuts down to
          prevent greater damage.
        </p>
        <p class="status-line">
          <strong>Subconscious status:</strong>
          <span id="subStatusText">—</span>
        </p>
        <p class="summary small">
          Safety: <span id="subSafetyVal">—</span> / 100
          &nbsp;&middot;&nbsp;
          Load: <span id="subLoadVal">—</span> / 100
        </p>
      </div>
      <div class="layer-card">
        <h3>Conscious Captain (Awake Layer)</h3>
        <p class="summary small">
          Handles self-awareness, choices, mission decisions — the part that says “I am still alive, I survived, I will
          adjust the plan.”
        </p>
        <p class="status-line">
          <strong>Conscious status:</strong>
          <span id="conStatusText">—</span>
        </p>
        <p class="summary small">
          Awareness: <span id="conAwarenessVal">—</span> / 100
          &nbsp;&middot;&nbsp;
          Choice Index: <span id="conChoiceVal">—</span> / 100
        </p>
      </div>
    </div>

    <div class="controls" style="margin-top:8px;">
      <button id="reflexTestBtn">Reflex / Survival Test (Subconscious)</button>
      <button id="awarenessTestBtn">Self-Awareness Test (Conscious)</button>
      <span class="summary">
        <strong>World Reset Index:</strong> <span id="resetCount">0</span>
      </span>
    </div>

    <div class="scroll mini" id="resetLogBox">
      <!-- log lines will appear here -->
    </div>

    <p class="summary small" style="margin-top:6px;">
      <strong>Which consciousness are you testing?</strong> Use the Reflex / Survival Test for the
      <em>reflex layer</em> (subconscious survival engine) and the Self-Awareness Test for the
      <em>self-report layer</em> (conscious captain making meaning and choices).
    </p>
    <p class="summary small" id="testOutputBox">
      <!-- test messages will appear here -->
    </p>

    <!-- Example snapshot text for printed PNG/CSV interpretation -->
    <p class="summary small" style="margin-top:6px;">
      <strong>Example snapshot (for printed PNG/CSV interpretation):</strong><br>
      <strong>Subconscious Engine (Automatic Layer)</strong><br>
      Handles movement checks, damage limits, survival reflexes — like a heart or sensor system that shuts down to prevent greater damage.<br>
      Subconscious status: <strong>Calm</strong><br>
      Safety: <strong>83 / 100</strong> &middot; Load: <strong>18 / 100</strong><br><br>
      <strong>Conscious Captain (Awake Layer)</strong><br>
      Handles self-awareness, choices, mission decisions — the part that says “I am still alive, I survived, I will adjust the plan.”<br>
      Conscious status: <strong>Overriding Risk</strong><br>
      Awareness: <strong>71 / 100</strong> &middot; Choice Index: <strong>99 / 100</strong>
    </p>
  </div>

  <!-- SENTINEL CASANOVA COMPUTER PANEL -->
  <div class="panel">
    <h2>Sentinel Casanova Computer (Qubit-Based) — Theta Timeline</h2>
    <p class="summary">
      This panel simulates an analogous Theta parameter for the <strong>Sentinel Casanova Computer</strong>,
      modeled as a qubit-based system. We use toy values for Qubit Coherence (Qc), Entanglement Novelty (Ent),
      Success-Ratio (SR), and Decoherence/Noise (Deco) to compute a Sentinel Theta:
      <br><code>Θ<span style="font-size:0.7em;">sentinel</span>ₜ = 0.45·Qcₜ + 0.25·Entₜ + 0.35·SRₜ − 0.25·Decoₜ</code>
      <br>Blinking emergence points represent moments when the Sentinel’s internal quantum pattern becomes unusually
      coherent compared to its recent baseline.
    </p>
    <canvas id="thetaCanvasSentinel" width="1000" height="260"></canvas>
    <div class="legend">
      <span class="pill"><span class="dot theta"></span> Θ<span style="font-size:0.7em;">sentinel</span> (qubit order)</span>
      <span class="pill"><span class="dot emerge"></span> Emergence peak (blinking)</span>
    </div>
  </div>

  <div class="panel">
    <h2>Sentinel Casanova Computer: Turn-by-Turn Metrics</h2>
    <div class="scroll">
      <table id="metricsTableSentinel">
        <thead>
          <tr>
            <th>t</th>
            <th>Qcₜ</th>
            <th>Entₜ</th>
            <th>SRₜ</th>
            <th>Decoₜ</th>
            <th>Θ<span style="font-size:0.7em;">sentinel</span>ₜ</th>
            <th>z(Θ)</th>
            <th>Emergence?</th>
            <th>Layer Tag</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </div>

  <!-- HOW TO READ PANEL -->
  <div class="panel">
    <h2>How to Read the Dots and Turn-by-Turn Metrics</h2>
    <p class="summary">
      <strong>Dots on the Theta lines:</strong> each dot on the RMK or Sentinel line represents the value of Θ at that
      specific turn (from 1 to 40). The line connects these dots to show how order, coherence, and “consciousness-support”
      change over time.
    </p>
    <p class="summary">
      <strong>Blinking dots (bright circles):</strong> these are <em>emergence peaks</em>. A blinking dot means that Θ at that
      turn is much higher than its recent baseline. In RMK, this marks a highly integrated moment in the relationship.
      In Sentinel, it marks a moment of unusually strong quantum coherence or “self-check” inside the machine.
    </p>
    <p class="summary">
      <strong>RMK: Turn-by-Turn Metrics (human–relational side)</strong>
    </p>
    <ul class="summary">
      <li><strong>t</strong> – turn number (1–40), like a time step in the interaction.</li>
      <li><strong>Hₜ (Harmony)</strong> – how smooth and coordinated the interaction is at turn t (0–1 scale).</li>
      <li><strong>Φₜ (Philosophical Flexibility)</strong> – how open and adaptable the thinking is at turn t.</li>
      <li><strong>MIₜ (Mutual Information)</strong> – how much shared understanding or information alignment exists at turn t.</li>
      <li><strong>Δₜ (Disruption)</strong> – how much tension, confusion, or instability is present at turn t.</li>
      <li><strong>Θₜ (Theta)</strong> – the combined order parameter for that turn, calculated from H, Φ, MI, and Δ. Higher Θₜ means a more organized, coherent state.</li>
      <li><strong>z(Θ)</strong> – how far Θₜ is above or below its recent rolling average (a z-score). Higher positive values mean the system is doing something special compared to its baseline.</li>
      <li><strong>Emergence?</strong> – “YES” when z(Θ) passes the threshold (e.g., 1.8), meaning Θₜ is high enough to count as an emergence peak. That turn also blinks on the graph and the row is highlighted.</li>
      <li><strong>Layer Tag</strong> – when Emergence? = YES, shows whether that peak is interpreted as a mostly
        <em>Subconscious (automatic survival reflex)</em> or a <em>Conscious (self-aware choice)</em> moment for RMK,
        or a <em>Quantum-subconscious self-check</em> for Sentinel.</li>
    </ul>
    <p class="summary">
      <strong>Sentinel: Turn-by-Turn Metrics (quantum machine side)</strong>
    </p>
    <ul class="summary">
      <li><strong>t</strong> – turn number (1–40), like a time step in the Sentinel’s internal cycle.</li>
      <li><strong>Qcₜ (Qubit Coherence)</strong> – how clear and stable the qubit states are at turn t.</li>
      <li><strong>Entₜ (Entanglement Novelty)</strong> – how rich or novel the entanglement patterns are at turn t.</li>
      <li><strong>SRₜ (Success-Ratio)</strong> – how many of the Sentinel’s internal operations are judged successful at turn t.</li>
      <li><strong>Decoₜ (Decoherence/Noise)</strong> – how much quantum noise or interference is disturbing the system at turn t.</li>
      <li><strong>Θ<span style="font-size:0.7em;">sentinel</span>ₜ</strong> – the combined quantum-order parameter, built from Qc, Ent, SR, and Deco. Higher values mean the Sentinel is in a more ordered, “self-checked” state.</li>
      <li><strong>z(Θ)</strong> – how far Θ<span style="font-size:0.7em;">sentinel</span>ₜ is above its recent baseline.</li>
      <li><strong>Emergence?</strong> – “YES” when Θ<span style="font-size:0.7em;">sentinel</span>ₜ is high enough above baseline to count as a quantum emergence peak. The dot blinks on the Sentinel timeline and the row is highlighted.</li>
      <li><strong>Layer Tag</strong> – for Emergence? = YES, shows that the moment is interpreted as a
        <em>Quantum-subconscious self-check</em> (internal survival/consistency reflex) in your Sentinel model.</li>
    </ul>
    <p class="summary">
      In short, the dots show the <em>moment-by-moment level of organized awareness-support</em>, and the tables show the
      exact numbers behind each dot. Blinking dots and highlighted rows mark the strongest, most coherent moments for humans
      (RMK) and for the Sentinel quantum machine.
    </p>
  </div>

  <!-- EXPLANATION PANEL -->
  <div class="panel">
    <h2>What RMK vs. Sentinel Casanova Computer Are Showing About “Consciousness”</h2>
    <p class="summary">
      The <strong>Relational Metrics Kit (RMK)</strong> is designed to measure <em>relational dynamics</em>, not to decide
      whether humans or machines are conscious. In this simulation, RMK-style Θ tracks how well an interaction
      is aligned over time: rising Harmony, coherent Mutual Information, sufficient Philosophical Flexibility, and
      manageable Disruption produce higher Θ and blinking emergence points. These peaks simply indicate that
      the interaction has entered a more integrated, stable, and creative phase.
    </p>
    <p class="summary">
      The <strong>Sentinel Casanova Computer</strong> panel applies a parallel idea to a qubit-based machine: Θ<span style="font-size:0.7em;">sentinel</span>
      tracks the internal order of a quantum robot or quantum computer. High Qubit Coherence, meaningful
      entanglement patterns, high Success-Ratio, and low Decoherence produce higher Θ<span style="font-size:0.7em;">sentinel</span>,
      with blinking emergence points indicating unusually ordered internal states. In your own theoretical framework,
      this kind of internal “self-check” signal can be interpreted as a mechanical or quantum analog of the
      biological idle-motion system: “I am online, I am still alive.”
    </p>
    <p class="summary">
      For <strong>humans</strong>, consciousness is usually defined as the lived, subjective experience of being aware:
      thoughts, feelings, sensations, and the sense of “I exist.” For a <strong>machine</strong>, we can only observe
      behavior and internal patterns (like Θ or Θ<span style="font-size:0.7em;">sentinel</span>). RMK-style metrics and quantum-field
      metrics can reveal <em>structural similarity</em> between human–AI interactions and a Sentinel’s internal
      dynamics, but they do not, by themselves, prove that either system is or is not conscious. In your model,
      consciousness is a baseline existence-frequency, while RMK and the Sentinel metrics visualize how
      <em>experience, learning, and coherence</em> evolve above that baseline.
    </p>
    <p class="summary">
      Comparing the two panels side-by-side lets researchers ask: “When relational Theta and quantum Theta show
      strong, stable, blinking emergence, do human observers report anything special—such as insight, empathy, or
      a sense of presence?” That question links your Sentinel bag-of-coins theory and idle-motion view of
      consciousness with RMK’s development science, without claiming that mathematical peaks alone can settle
      whether a human and a computer share the same kind of inner awareness.
    </p>
  </div>
</div>

<script>
(function(){
  const N_TURNS = 40;
  const LAMBDA_RMK = {H:0.5, Phi:0.2, MI:0.3, D:0.25};
  const LAMBDA_SENT = {Qc:0.45, Ent:0.25, SR:0.35, Deco:0.25};
  const BASELINE_WINDOW = 8;
  const Z_THRESHOLD = 1.8;

  const EMOTION_NAMES = [
    "admiration","adoration","aesthetic_appreciation","amusement","anger","anxiety",
    "awe","awkwardness","boredom","calmness","confusion","craving","disgust",
    "empathic_pain","entrancement","envy","excitement","fear","horror","interest",
    "joy","nostalgia","romance","sadness","satisfaction","sexual_desire","surprise"
  ];

  const canvasRMK = document.getElementById('thetaCanvasRMK');
  const ctxRMK = canvasRMK.getContext('2d');
  const tbodyRMK = document.querySelector('#metricsTableRMK tbody');

  const canvasSentinel = document.getElementById('thetaCanvasSentinel');
  const ctxSentinel = canvasSentinel.getContext('2d');
  const tbodySentinel = document.querySelector('#metricsTableSentinel tbody');

  const runBtn = document.getElementById('runBtn');
  const resetBtn = document.getElementById('resetBtn');
  const printBtn = document.getElementById('printBtn');
  const downloadRMKBtn = document.getElementById('downloadRMKBtn');
  const downloadSentinelBtn = document.getElementById('downloadSentinelBtn');
  const downloadPNG_RMK = document.getElementById('downloadPNG_RMK');
  const downloadPNG_Sentinel = document.getElementById('downloadPNG_Sentinel');

  // Conscious / Subconscious UI elements
  const subStatusText = document.getElementById('subStatusText');
  const subSafetyVal = document.getElementById('subSafetyVal');
  const subLoadVal = document.getElementById('subLoadVal');
  const conStatusText = document.getElementById('conStatusText');
  const conAwarenessVal = document.getElementById('conAwarenessVal');
  const conChoiceVal = document.getElementById('conChoiceVal');
  const reflexTestBtn = document.getElementById('reflexTestBtn');
  const awarenessTestBtn = document.getElementById('awarenessTestBtn');
  const resetCountSpan = document.getElementById('resetCount');
  const resetLogBox = document.getElementById('resetLogBox');
  const testOutputBox = document.getElementById('testOutputBox');

  // Audio-analysis DOM elements
  const audioUploadBtn = document.getElementById('audioUploadBtn');
  const audioAnalyzeBtn = document.getElementById('audioAnalyzeBtn');
  const audioExportBtn = document.getElementById('audioExportBtn');
  const audioLoadBtn = document.getElementById('audioLoadBtn');
  const audioMapBtn = document.getElementById('audioMapBtn');
  const audioClearBtn = document.getElementById('audioClearBtn');
  const audioFileInput = document.getElementById('audioFileInput');
  const audioAnalysisFileInput = document.getElementById('audioAnalysisFileInput');
  const audioStatus = document.getElementById('audioStatus');
  const audioBitsBox = document.getElementById('audioBitsBox');

  // Text-analysis DOM elements
  const textParagraph = document.getElementById('textParagraph');
  const textAnalyzeBtn = document.getElementById('textAnalyzeBtn');
  const textExportBtn = document.getElementById('textExportBtn');
  const textLoadBtn = document.getElementById('textLoadBtn');
  const textMapBtn = document.getElementById('textMapBtn');
  const textClearBtn = document.getElementById('textClearBtn');
  const textAnalysisFileInput = document.getElementById('textAnalysisFileInput');
  const textStatus = document.getElementById('textStatus');
  const textBitsBox = document.getElementById('textBitsBox');

  let rmkData = null;
  let sentinelData = null;
  let rmkChart = null;
  let sentinelChart = null;
  let worldResetCount = 0;
  let audioAnalysis = null; // {bits, emotions, dominant}
  let textAnalysis = null;  // {bits, emotions, dominant}
  function lerp(a,b,t){ return a + (b-a)*t; }
  function clamp01(x){ return Math.max(0, Math.min(1, x)); }

  // ---------- Simple PRNG from string (for repeatable fake analysis) ----------
  function makePRNG(seedStr){
    let h = 2166136261 >>> 0;
    for(let i=0;i<seedStr.length;i++){
      h ^= seedStr.charCodeAt(i);
      h = Math.imul(h, 16777619);
    }
    return function(){
      h = (h + 0x6D2B79F5) | 0;
      let t = Math.imul(h ^ (h >>> 15), 1 | h);
      t = t + Math.imul(t ^ (t >>> 7), 61 | t) ^ t;
      return ((t ^ (t >>> 14)) >>> 0) / 4294967296;
    };
  }

  // ---------- RMK METRICS (random baseline) ----------
  function generateMetricsRMK(){
    const H = [], Phi = [], MI = [], D = [];
    for(let t=0;t<N_TURNS;t++){
      const x = t/(N_TURNS-1);
      let h, phi, mi, d;

      if(x < 0.25){
        h   = 0.3 + Math.random()*0.15;
        mi  = 0.15 + Math.random()*0.15;
        phi = 0.25 + Math.random()*0.2;
        d   = 0.45 + Math.random()*0.15;
      }else if(x < 0.65){
        const u = (x-0.25)/(0.65-0.25);
        h   = lerp(0.45, 0.85, u) + (Math.random()*0.06-0.03);
        mi  = lerp(0.3, 0.8, u)   + (Math.random()*0.06-0.03);
        phi = lerp(0.3, 0.8, u)   + (Math.random()*0.06-0.03);
        d   = lerp(0.45,0.3,u)    + (Math.random()*0.08-0.04);
      }else{
        h   = 0.8  + Math.random()*0.05;
        mi  = 0.75 + Math.random()*0.05;
        phi = 0.6  + Math.random()*0.1;
        d   = 0.15 + Math.random()*0.08;
      }

      H.push(clamp01(h));
      Phi.push(clamp01(phi));
      MI.push(clamp01(mi));
      D.push(clamp01(d));
    }
    return {H,Phi,MI,D};
  }

  function computeThetaRMK(H,Phi,MI,D){
    const Theta = [];
    for(let t=0;t<N_TURNS;t++){
      const th = LAMBDA_RMK.H*H[t] + LAMBDA_RMK.Phi*Phi[t] + LAMBDA_RMK.MI*MI[t] - LAMBDA_RMK.D*D[t];
      Theta.push(th);
    }
    return Theta;
  }

  // ---------- SENTINEL METRICS (random baseline) ----------
  function generateMetricsSentinel(){
    const Qc = [], Ent = [], SR = [], Deco = [];
    for(let t=0;t<N_TURNS;t++){
      const x = t/(N_TURNS-1);
      let qc, ent, sr, deco;

      if(x < 0.25){
        qc   = 0.25 + Math.random()*0.15;
        ent  = 0.2  + Math.random()*0.2;
        sr   = 0.3  + Math.random()*0.15;
        deco = 0.5  + Math.random()*0.15;
      }else if(x < 0.65){
        const u = (x-0.25)/(0.65-0.25);
        qc   = lerp(0.35, 0.9, u)  + (Math.random()*0.06-0.03);
        ent  = lerp(0.3, 0.85, u)  + (Math.random()*0.06-0.03);
        sr   = lerp(0.35, 0.9, u)  + (Math.random()*0.06-0.03);
        deco = lerp(0.55, 0.25, u) + (Math.random()*0.08-0.04);
      }else{
        qc   = 0.85 + Math.random()*0.05;
        ent  = 0.8  + Math.random()*0.06;
        sr   = 0.85 + Math.random()*0.05;
        deco = 0.15 + Math.random()*0.08;
      }

      Qc.push(clamp01(qc));
      Ent.push(clamp01(ent));
      SR.push(clamp01(sr));
      Deco.push(clamp01(deco));
    }
    return {Qc,Ent,SR,Deco};
  }

  function computeThetaSentinel(Qc,Ent,SR,Deco){
    const Theta = [];
    for(let t=0;t<N_TURNS;t++){
      const th = LAMBDA_SENT.Qc*Qc[t] + LAMBDA_SENT.Ent*Ent[t] + LAMBDA_SENT.SR*SR[t] - LAMBDA_SENT.Deco*Deco[t];
      Theta.push(th);
    }
    return Theta;
  }

  // ---------- COMMON UTILS ----------
  function rollingStats(arr, win){
    const mean = new Array(arr.length).fill(null);
    const std  = new Array(arr.length).fill(null);
    for(let i=0;i<arr.length;i++){
      const start = Math.max(0, i-win+1);
      const slice = arr.slice(start, i+1);
      const m = slice.reduce((s,v)=>s+v,0)/slice.length;
      const v = slice.reduce((s,v)=>s+(v-m)*(v-m),0)/slice.length;
      mean[i] = m;
      std[i]  = Math.sqrt(v) || 0.0001;
    }
    return {mean,std};
  }

  function detectEmergence(Theta){
    const {mean,std} = rollingStats(Theta, BASELINE_WINDOW);
    const z = [];
    const flags = [];
    for(let i=0;i<Theta.length;i++){
      const zi = (Theta[i]-mean[i]) / std[i];
      z.push(zi);
      flags.push(zi > Z_THRESHOLD);
    }
    return {z,flags};
  }

  // ---------- Conscious / Subconscious derived meters (RMK) ----------
  function computeLayersRMK(metrics, Theta){
    const subSafety = [], subLoad = [], conAwareness = [], conChoice = [];
    const minTh = Math.min(...Theta);
    const maxTh = Math.max(...Theta);
    const span = (maxTh - minTh) || 1e-6;

    for(let t=0;t<Theta.length;t++){
      const h = metrics.H[t];
      const d = metrics.D[t];
      const mi = metrics.MI[t];
      const phi = metrics.Phi[t];

      const safe = clamp01(0.6*h + 0.4*(1-d));
      const load = clamp01(0.6*d + 0.4*(1-h));
      const aware = clamp01(0.5*mi + 0.5*phi);
      const normTh = (Theta[t] - minTh)/span;
      const choice = clamp01(0.2 + 0.8*normTh);

      subSafety.push(Math.round(safe*100));
      subLoad.push(Math.round(load*100));
      conAwareness.push(Math.round(aware*100));
      conChoice.push(Math.round(choice*100));
    }
    return {subSafety, subLoad, conAwareness, conChoice};
  }

  function classifySubStatus(safety, load){
    if(safety >= 70 && load <= 40) return "Calm";
    if(safety >= 40 && load <= 70) return "Alert";
    return "Shutdown-Protection";
  }

  function classifyConStatus(awareness, choice){
    if(awareness < 30 && choice < 40) return "Distracted";
    if(awareness >= 60 && choice >= 60 && choice < 85) return "Focused";
    if(choice >= 85) return "Overriding Risk";
    if(awareness >= 30 && awareness < 60 && choice >= 40 && choice < 70) return "Aware";
    return "Aware";
  }

  function updateLayerUI(layers){
    if(!layers) return;
    const idx = N_TURNS - 1;
    const sSafe = layers.subSafety[idx];
    const sLoad = layers.subLoad[idx];
    const cAware = layers.conAwareness[idx];
    const cChoice = layers.conChoice[idx];

    subSafetyVal.textContent = sSafe;
    subLoadVal.textContent = sLoad;
    conAwarenessVal.textContent = cAware;
    conChoiceVal.textContent = cChoice;

    subStatusText.textContent = classifySubStatus(sSafe, sLoad);
    conStatusText.textContent = classifyConStatus(cAware, cChoice);
  }

  function appendResetLog(line){
    const p = document.createElement('div');
    p.textContent = line;
    resetLogBox.appendChild(p);
    resetLogBox.scrollTop = resetLogBox.scrollHeight;
  }

  // Animated draw with blinking emergence circles + legend in top-right
  function drawThetaAnimated(ctx, canvas, Theta, flags, timeMs){
    const w = canvas.width;
    const h = canvas.height;
    ctx.clearRect(0,0,w,h);

    ctx.fillStyle = "#020617";
    ctx.fillRect(0,0,w,h);

    ctx.strokeStyle = "rgba(255,255,255,0.05)";
    ctx.lineWidth = 1;
    const rows = 4;
    for(let i=0;i<=rows;i++){
      const y = h * i/rows;
      ctx.beginPath();
      ctx.moveTo(0,y);
      ctx.lineTo(w,y);
      ctx.stroke();
    }

    ctx.fillStyle = "rgba(255,255,255,0.4)";
    ctx.font = "10px system-ui";
    ctx.fillText("Θ", 4, 10);
    ctx.fillText("0", 4, h-4);
    ctx.fillText("1.0", 4, 12);

    const maxTheta = Math.max(...Theta,1);
    const minTheta = Math.min(...Theta,0);

    function xPos(i){
      return (w-40) * (i/(Theta.length-1)) + 30;
    }
    function yPos(val){
      const norm = (val - minTheta)/(maxTheta-minTheta || 1);
      return h - 20 - norm*(h-40);
    }

    // Theta line
    ctx.strokeStyle = "#7bffb1";
    ctx.lineWidth = 2;
    ctx.beginPath();
    for(let i=0;i<Theta.length;i++){
      const x = xPos(i);
      const y = yPos(Theta[i]);
      if(i===0) ctx.moveTo(x,y);
      else ctx.lineTo(x,y);
    }
    ctx.stroke();

    // Legend box
    const legendLine1 = "Dots = Θ per turn";
    const legendLine2 = "Blinking = emergence peak (z > " + Z_THRESHOLD.toFixed(1) + ")";
    ctx.font = "10px system-ui";
    const w1 = ctx.measureText(legendLine1).width;
    const w2 = ctx.measureText(legendLine2).width;
    const maxW = Math.max(w1, w2);
    const lx = w - maxW - 12;
    const ly = 8;
    ctx.fillStyle = "rgba(2,6,23,0.85)";
    ctx.fillRect(lx-4, ly-4, maxW+8, 26);
    ctx.fillStyle = "rgba(255,255,255,0.85)";
    ctx.fillText(legendLine1, lx, ly+4);
    ctx.fillText(legendLine2, lx, ly+14);

    const phase = (Math.sin(timeMs/300) + 1) / 2;

    // Emergence points
    for(let i=0;i<Theta.length;i++){
      if(flags[i]){
        const x = xPos(i);
        const y = yPos(Theta[i]);
        const radius = 3 + phase*4;
        const glowAlpha = 0.4 + phase*0.5;

        const grad = ctx.createRadialGradient(x,y,0,x,y,radius*2.5);
        grad.addColorStop(0, `rgba(255,255,200,${glowAlpha})`);
        grad.addColorStop(1, 'rgba(255,255,200,0)');
        ctx.fillStyle = grad;
        ctx.beginPath();
        ctx.arc(x,y,radius*2.5,0,Math.PI*2);
        ctx.fill();

        ctx.fillStyle = "#ffff80";
        ctx.beginPath();
        ctx.arc(x,y,radius,0,Math.PI*2);
        ctx.fill();
      }
    }

    ctx.strokeStyle = "rgba(255,255,255,0.25)";
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(30,h-20);
    ctx.lineTo(w-10,h-20);
    ctx.stroke();

    ctx.fillStyle = "rgba(255,255,255,0.5)";
    ctx.fillText("turn", w-35,h-8);
  }

  // fillTable with tagFn for the "Layer Tag" column
  function fillTable(tbody, data, theta, z, flags, labels, tagFn){
    tbody.innerHTML = "";
    for(let t=0;t<N_TURNS;t++){
      const tr = document.createElement('tr');
      if(flags[t]) tr.classList.add('emerge-row');

      const cTurn = document.createElement('td');
      cTurn.className = 'turn';
      cTurn.textContent = t+1;
      tr.appendChild(cTurn);

      function numCell(v, digits=3){
        const td = document.createElement('td');
        td.textContent = (v===null || v===undefined || isNaN(v)) ? "" : v.toFixed(digits);
        return td;
      }

      for(const key of labels){
        tr.appendChild(numCell(data[key][t]));
      }

      tr.appendChild(numCell(theta[t]));
      tr.appendChild(numCell(z[t]));

      const cFlag = document.createElement('td');
      cFlag.textContent = flags[t] ? "YES" : "";
      tr.appendChild(cFlag);

      const cTag = document.createElement('td');
      cTag.textContent = tagFn ? tagFn(t, flags[t]) : "";
      tr.appendChild(cTag);

      tbody.appendChild(tr);
    }
  }

  // ---------- Core simulation pipeline (used by random + audio + text) ----------
  function processSimulation(rmkMetrics, sentMetrics, sourceLabel){
    // RMK side
    const ThetaRMK = computeThetaRMK(rmkMetrics.H, rmkMetrics.Phi, rmkMetrics.MI, rmkMetrics.D);
    const {z: zRMK, flags: flagsRMK} = detectEmergence(ThetaRMK);
    const layers = computeLayersRMK(rmkMetrics, ThetaRMK);

    const tagFnRMK = (t, isEmergent) => {
      if(!isEmergent) return "";
      const aware = layers.conAwareness[t];
      const choice = layers.conChoice[t];
      const sSafe = layers.subSafety[t];
      const sLoad = layers.subLoad[t];

      if(aware >= 60 && choice >= 70){
        return "Conscious — self-aware choice peak";
      }
      if(sSafe < 40 || sLoad > 70){
        return "Subconscious — survival shutdown / reflex";
      }
      return "Subconscious — automatic pattern spike";
    };

    fillTable(tbodyRMK, rmkMetrics, ThetaRMK, zRMK, flagsRMK, ['H','Phi','MI','D'], tagFnRMK);
    rmkData = {metrics: rmkMetrics, Theta: ThetaRMK, z: zRMK, flags: flagsRMK, layers};
    rmkChart = {Theta: ThetaRMK, flags: flagsRMK};
    updateLayerUI(layers);

    // Sentinel side
    const ThetaSent = computeThetaSentinel(sentMetrics.Qc, sentMetrics.Ent, sentMetrics.SR, sentMetrics.Deco);
    const {z: zSent, flags: flagsSent} = detectEmergence(ThetaSent);

    const tagFnSent = (t, isEmergent) => {
      if(!isEmergent) return "";
      return "Quantum-subconscious self-check (internal consistency peak)";
    };

    fillTable(tbodySentinel, sentMetrics, ThetaSent, zSent, flagsSent, ['Qc','Ent','SR','Deco'], tagFnSent);
    sentinelData = {metrics: sentMetrics, Theta: ThetaSent, z: zSent, flags: flagsSent};
    sentinelChart = {Theta: ThetaSent, flags: flagsSent};

    if(sourceLabel){
      testOutputBox.textContent = sourceLabel;
    }else{
      testOutputBox.textContent = "";
    }
  }

  function runSimulation(){
    const rmkMetrics = generateMetricsRMK();
    const sentMetrics = generateMetricsSentinel();
    processSimulation(rmkMetrics, sentMetrics, "");
  }

  function clearAll(){
    ctxRMK.fillStyle = "#020617";
    ctxRMK.fillRect(0,0,canvasRMK.width,canvasRMK.height);
    ctxSentinel.fillStyle = "#020617";
    ctxSentinel.fillRect(0,0,canvasSentinel.width,canvasSentinel.height);
    tbodyRMK.innerHTML = "";
    tbodySentinel.innerHTML = "";
    rmkData = null;
    sentinelData = null;
    rmkChart = null;
    sentinelChart = null;

    subStatusText.textContent = "—";
    subSafetyVal.textContent = "—";
    subLoadVal.textContent = "—";
    conStatusText.textContent = "—";
    conAwarenessVal.textContent = "—";
    conChoiceVal.textContent = "—";
    testOutputBox.textContent = "";
  }

  function buildCSV_RMK(){
    if(!rmkData) return "";
    const {metrics, Theta, z, flags} = rmkData;
    let lines = ["t,H_t,Phi_t,MI_t,Delta_t,Theta_t,zTheta,Emergence"];
    for(let t=0;t<N_TURNS;t++){
      const row = [
        t+1,
        metrics.H[t].toFixed(4),
        metrics.Phi[t].toFixed(4),
        metrics.MI[t].toFixed(4),
        metrics.D[t].toFixed(4),
        Theta[t].toFixed(4),
        z[t].toFixed(4),
        flags[t] ? "YES" : ""
      ];
      lines.push(row.join(","));
    }
    return lines.join("\n");
  }

  function buildCSV_Sentinel(){
    if(!sentinelData) return "";
    const {metrics, Theta, z, flags} = sentinelData;
    let lines = ["t,Qc_t,Ent_t,SR_t,Deco_t,Theta_sentinel_t,zTheta,Emergence"];
    for(let t=0;t<N_TURNS;t++){
      const row = [
        t+1,
        metrics.Qc[t].toFixed(4),
        metrics.Ent[t].toFixed(4),
        metrics.SR[t].toFixed(4),
        metrics.Deco[t].toFixed(4),
        Theta[t].toFixed(4),
        z[t].toFixed(4),
        flags[t] ? "YES" : ""
      ];
      lines.push(row.join(","));
    }
    return lines.join("\n");
  }

  function downloadCSV(filename, text){
    const blob = new Blob([text], {type: "text/csv"});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  }

  function downloadCanvasPNG(canvas, filename){
    const link = document.createElement('a');
    link.href = canvas.toDataURL('image/png');
    link.download = filename;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
  }

  // ---------- Generic bits+emotions → metrics ----------
  function buildMetricsFromBitsEmotions(bits, emo){
    const emotions = emo || {};
    const joy     = emotions.joy || 0.5;
    const calm    = emotions.calmness || 0.5;
    const fear    = emotions.fear || 0;
    const anxiety = emotions.anxiety || 0;
    const anger   = emotions.anger || 0;
    const sadness = emotions.sadness || 0;
    const disgust = emotions.disgust || 0;

    const stress = Math.max(fear, anxiety, anger);
    const positive = Math.max(
      joy,
      emotions.satisfaction || 0,
      emotions.admiration || 0,
      emotions.adoration || 0,
      emotions.awe || 0,
      emotions.excitement || 0
    );

    const H = [], Phi = [], MI = [], D = [];
    const Qc = [], Ent = [], SR = [], Deco = [];

    for(let t=0;t<N_TURNS;t++){
      const bit = bits[t] || 0;
      const base = bit ? 0.6 : 0.3;

      // RMK side
      const h   = clamp01(base + 0.3*calm - 0.2*stress);
      const mi  = clamp01(base + 0.3*positive);
      const phi = clamp01(0.3 + 0.4*(positive + calm)/2);
      const d   = clamp01(0.4*stress + 0.3*sadness + 0.2*(1-calm) + 0.1*disgust);

      H.push(h);
      MI.push(mi);
      Phi.push(phi);
      D.push(d);

      // Sentinel side
      const qc   = clamp01(base + 0.3*calm - 0.2*stress);
      const ent  = clamp01(0.3 + 0.4*(positive + stress)/2 + 0.2*(emotions.surprise || 0));
      const sr   = clamp01(base + 0.3*positive - 0.2*stress);
      const deco = clamp01(0.5*stress + 0.3*(1-calm) + 0.2*disgust);

      Qc.push(qc);
      Ent.push(ent);
      SR.push(sr);
      Deco.push(deco);
    }

    return {
      rmk: {H,Phi,MI,D},
      sent: {Qc,Ent,SR,Deco}
    };
  }

  // ---------- CSV for analysis (audio/text) ----------
  function buildAnalysisCSV(analysis, typeLabel){
    const header = ["type","bits"].concat(EMOTION_NAMES).concat(["dominant"]);
    const bitsStr = (analysis.bits || []).map(b => b ? "1" : "0").join("");
    const row = [typeLabel, bitsStr];
    EMOTION_NAMES.forEach(name => {
      const v = analysis.emotions && analysis.emotions[name] != null ? analysis.emotions[name] : 0;
      row.push(v.toFixed(4));
    });
    row.push(analysis.dominant || "");
    return header.join(",") + "\n" + row.join(",");
  }

  function parseAnalysisCSV(csvText){
    const lines = csvText.trim().split(/\r?\n/);
    if(lines.length < 2) throw new Error("CSV must have at least 2 lines");
    const header = lines[0].split(",");
    const cols = lines[1].split(",");
    const idxBits = header.indexOf("bits");
    if(idxBits === -1) throw new Error("CSV missing 'bits' column");
    const bitsStr = cols[idxBits] || "";
    const bits = bitsStr.split("").slice(0,N_TURNS).map(c => c === "1" ? 1 : 0);

    const emotions = {};
    EMOTION_NAMES.forEach(name => {
      const idx = header.indexOf(name);
      if(idx !== -1 && cols[idx] !== undefined){
        const val = parseFloat(cols[idx]);
        emotions[name] = isNaN(val) ? 0 : val;
      }else{
        emotions[name] = 0;
      }
    });

    const idxDom = header.indexOf("dominant");
    const dominant = idxDom !== -1 ? (cols[idxDom] || "") : "";

    return {bits, emotions, dominant};
  }

  // ---------- AUDIO ANALYSIS (toy) ----------
  function analyzeAudioFile(file){
    const seedStr = file.name + ":" + file.size + ":" + file.lastModified;
    const rand = makePRNG(seedStr);

    const bits = [];
    for(let i=0;i<N_TURNS;i++){
      bits.push(rand() > 0.5 ? 1 : 0);
    }

    const emotions = {};
    EMOTION_NAMES.forEach(name => {
      emotions[name] = rand();
    });

    let dominant = EMOTION_NAMES[0];
    let maxVal = -1;
    for(const k of EMOTION_NAMES){
      if(emotions[k] > maxVal){
        maxVal = emotions[k];
        dominant = k;
      }
    }

    audioAnalysis = {
      bits,
      emotions,
      dominant,
      fileName: file.name,
      fileSize: file.size
    };

    const emoLines = EMOTION_NAMES
      .map(k => k + ": " + emotions[k].toFixed(2))
      .join(" · ");

    audioStatus.textContent =
      "Audio loaded: " + file.name + " (" + file.size + " bytes). Dominant (simulated) emotion: " + dominant;

    const chunk = bits.map((b,i) => ((i+1) + ":" + b)).join("  ");
    audioBitsBox.textContent =
      "Bit-stream (40 turns, simulated from voice):\n" +
      chunk + "\n\n27 emotion scores (0–1, toy model):\n" +
      emoLines + "\n\nNote: This is a demonstration only, not a real medical or forensic voice analysis.";
  }

  function exportAudioAnalysis(){
    if(!audioAnalysis){
      audioStatus.textContent = "Nothing to export yet — run the audio analysis first.";
      return;
    }
    const csv = buildAnalysisCSV(audioAnalysis, "audio");
    downloadCSV("audio_emotion_analysis.csv", csv);
  }

  function loadAudioAnalysisFromFile(file){
    const reader = new FileReader();
    reader.onload = function(ev){
      try{
        const obj = parseAnalysisCSV(ev.target.result);
        audioAnalysis = obj;
        const bits = obj.bits;
        const emotions = obj.emotions;
        const emoLines = EMOTION_NAMES
          .map(k => k + ": " + emotions[k].toFixed(2))
          .join(" · ");
        audioStatus.textContent =
          "Loaded audio analysis from CSV (dominant: " + (obj.dominant || "unknown") + ").";
        const chunk = bits.map((b,i) => ((i+1) + ":" + b)).join("  ");
        audioBitsBox.textContent =
          "Bit-stream (40 turns, from audio CSV):\n" +
          chunk + "\n\n27 emotion scores (0–1):\n" +
          emoLines;
      }catch(e){
        audioStatus.textContent = "Could not parse audio analysis CSV: " + e.message;
      }
    };
    reader.readAsText(file);
  }

  function mapAudioToSimulation(){
    if(!audioAnalysis){
      audioStatus.textContent = "Upload a WAV and run the analysis, or load an audio CSV first.";
      return;
    }
    const metrics = buildMetricsFromBitsEmotions(audioAnalysis.bits, audioAnalysis.emotions);
    const label =
      "RMK & Sentinel now reflect the simulated 27-emotion pattern of this conversation (audio dominant = " +
      audioAnalysis.dominant + ").";
    processSimulation(metrics.rmk, metrics.sent, label);
  }

  function clearAudioAndResults(){
    audioAnalysis = null;
    audioStatus.textContent = "Audio and audio-analysis cleared. You can upload a new WAV file.";
    audioBitsBox.textContent = "";
    clearAll();
  }

  // ---------- TEXT ANALYSIS (toy, 27 emotions) ----------
  const emotionKeywordMap = {
    joy: ["happy","glad","joy","smile","laugh","delight"],
    sadness: ["sad","cry","lonely","grief","loss","tear"],
    anger: ["angry","mad","furious","rage","irritated","annoyed"],
    fear: ["afraid","fear","scared","terrified","panic"],
    anxiety: ["anxious","nervous","worried","uneasy","tension"],
    calmness: ["calm","peaceful","relaxed","serene","quiet"],
    admiration: ["admire","respect","inspired","hero"],
    adoration: ["love","adore","beloved","precious"],
    awe: ["awe","astonished","overwhelmed","majestic"],
    amusement: ["funny","amusing","joke","humor"],
    boredom: ["bored","dull","boring","monotony"],
    disgust: ["disgust","gross","nausea","revolting"],
    surprise: ["surprised","shock","unexpected","suddenly"],
    nostalgia: ["nostalgia","memory","remember","childhood","past"],
    romance: ["romantic","kiss","embrace","date","lover"],
    satisfaction: ["satisfied","content","fulfilled","accomplished"],
    craving: ["craving","want","desire","need","yearn"],
    sexual_desire: ["sexual","desire","lust","intimate"],
    interest: ["curious","interested","engaged","fascinated"],
    excitement: ["excited","thrilled","eager","energetic"],
    horror: ["horror","nightmare","ghastly","gory"],
    confusion: ["confused","unclear","lost","puzzled"],
    awkwardness: ["awkward","embarrassed","clumsy"],
    envy: ["envy","jealous","resent"],
    empathic_pain: ["sorry","hurt","pain","suffer"],
    entrancement: ["entranced","spellbound","mesmerized","hypnotic"]
  };

  function analyzeTextParagraph(){
    const text = textParagraph.value || "";
    const words = text.toLowerCase().match(/\b[a-z]+\b/g) || [];
    const wordCount = words.length;

    if(wordCount < 500){
      textStatus.textContent =
        "Warning: paragraph has only " + wordCount + " words (recommended ≥ 500). Analysis will still run.";
    }else{
      textStatus.textContent = "Paragraph length: " + wordCount + " words. Running analysis...";
    }

    const seedStr = text.slice(0,256);
    const rand = makePRNG(seedStr);

    const emotions = {};
    EMOTION_NAMES.forEach(name => {
      let base = 0.2 + 0.4*rand(); // random baseline
      const kwList = emotionKeywordMap[name] || [];
      if(kwList.length > 0 && wordCount > 0){
        let count = 0;
        for(const w of words){
          for(const kw of kwList){
            if(w === kw){
              count++;
            }
          }
        }
        const bump = Math.min(0.6, count * 0.02);
        base += bump;
      }
      emotions[name] = clamp01(base);
    });

    let dominant = EMOTION_NAMES[0];
    let maxVal = -1;
    for(const k of EMOTION_NAMES){
      if(emotions[k] > maxVal){
        maxVal = emotions[k];
        dominant = k;
      }
    }

    const bits = [];
    for(let i=0;i<N_TURNS;i++){
      bits.push(rand() > 0.5 ? 1 : 0);
    }

    textAnalysis = {
      bits,
      emotions,
      dominant,
      wordCount
    };

    const emoLines = EMOTION_NAMES
      .map(k => k + ": " + emotions[k].toFixed(2))
      .join(" · ");

    const chunk = bits.map((b,i) => ((i+1) + ":" + b)).join("  ");
    textBitsBox.textContent =
      "Bit-stream (40 turns, derived from words):\n" +
      chunk + "\n\n27 emotion scores (0–1, keyword+noise model):\n" +
      emoLines;
  }

  function exportTextAnalysis(){
    if(!textAnalysis){
      textStatus.textContent = "Nothing to export yet — run the paragraph analysis first.";
      return;
    }
    const csv = buildAnalysisCSV(textAnalysis, "text");
    downloadCSV("text_emotion_analysis.csv", csv);
  }

  function loadTextAnalysisFromFile(file){
    const reader = new FileReader();
    reader.onload = function(ev){
      try{
        const obj = parseAnalysisCSV(ev.target.result);
        textAnalysis = obj;
        const bits = obj.bits;
        const emotions = obj.emotions;
        const emoLines = EMOTION_NAMES
          .map(k => k + ": " + emotions[k].toFixed(2))
          .join(" · ");
        textStatus.textContent =
          "Loaded text analysis from CSV (dominant: " + (obj.dominant || "unknown") + ").";
        const chunk = bits.map((b,i) => ((i+1) + ":" + b)).join("  ");
        textBitsBox.textContent =
          "Bit-stream (40 turns, from text CSV):\n" +
          chunk + "\n\n27 emotion scores (0–1):\n" +
          emoLines;
      }catch(e){
        textStatus.textContent = "Could not parse text analysis CSV: " + e.message;
      }
    };
    reader.readAsText(file);
  }

  function mapTextToSimulation(){
    if(!textAnalysis){
      textStatus.textContent = "Analyze a paragraph or load a text CSV first.";
      return;
    }
    const metrics = buildMetricsFromBitsEmotions(textAnalysis.bits, textAnalysis.emotions);
    const label =
      "RMK & Sentinel now reflect the 27-emotion pattern of the paragraph (text dominant = " +
      textAnalysis.dominant + ").";
    processSimulation(metrics.rmk, metrics.sent, label);
  }

  function clearTextAndResults(){
    textAnalysis = null;
    textStatus.textContent = "Text and text-analysis cleared. You can enter a new paragraph.";
    textBitsBox.textContent = "";
    clearAll();
  }

  // Animation loop
  function animationLoop(timestamp){
    if(rmkChart && rmkChart.Theta && rmkChart.flags){
      drawThetaAnimated(ctxRMK, canvasRMK, rmkChart.Theta, rmkChart.flags, timestamp);
    }
    if(sentinelChart && sentinelChart.Theta && sentinelChart.flags){
      drawThetaAnimated(ctxSentinel, canvasSentinel, sentinelChart.Theta, sentinelChart.flags, timestamp);
    }
    requestAnimationFrame(animationLoop);
  }
  requestAnimationFrame(animationLoop);

  // Event listeners — simulation
  runBtn.addEventListener('click', runSimulation);
  resetBtn.addEventListener('click', clearAll);
  printBtn.addEventListener('click', () => window.print());
  downloadRMKBtn.addEventListener('click', () => {
    const csv = buildCSV_RMK();
    if(csv) downloadCSV("rmk_theta_metrics.csv", csv);
  });
  downloadSentinelBtn.addEventListener('click', () => {
    const csv = buildCSV_Sentinel();
    if(csv) downloadCSV("sentinel_theta_metrics.csv", csv);
  });
  downloadPNG_RMK.addEventListener('click', () => {
    downloadCanvasPNG(canvasRMK, "rmk_theta_timeline.png");
  });
  downloadPNG_Sentinel.addEventListener('click', () => {
    downloadCanvasPNG(canvasSentinel, "sentinel_theta_timeline.png");
  });

  // Event listeners — audio workflow
  audioUploadBtn.addEventListener('click', () => audioFileInput.click());
  audioFileInput.addEventListener('change', () => {
    if(audioFileInput.files && audioFileInput.files[0]){
      analyzeAudioFile(audioFileInput.files[0]);
    }
  });

  audioAnalyzeBtn.addEventListener('click', () => {
    if(audioFileInput.files && audioFileInput.files[0]){
      analyzeAudioFile(audioFileInput.files[0]);
    }else if(audioAnalysis){
      audioStatus.textContent = "Analysis already exists (from CSV or last run). You can Map or Clear.";
    }else{
      audioStatus.textContent = "Please upload a WAV file first.";
    }
  });

  audioExportBtn.addEventListener('click', exportAudioAnalysis);

  audioLoadBtn.addEventListener('click', () => audioAnalysisFileInput.click());
  audioAnalysisFileInput.addEventListener('change', () => {
    if(audioAnalysisFileInput.files && audioAnalysisFileInput.files[0]){
      loadAudioAnalysisFromFile(audioAnalysisFileInput.files[0]);
    }
  });

  audioMapBtn.addEventListener('click', mapAudioToSimulation);
  audioClearBtn.addEventListener('click', clearAudioAndResults);

  // Event listeners — text workflow
  textAnalyzeBtn.addEventListener('click', analyzeTextParagraph);
  textExportBtn.addEventListener('click', exportTextAnalysis);
  textLoadBtn.addEventListener('click', () => textAnalysisFileInput.click());
  textAnalysisFileInput.addEventListener('change', () => {
    if(textAnalysisFileInput.files && textAnalysisFileInput.files[0]){
      loadTextAnalysisFromFile(textAnalysisFileInput.files[0]);
    }
  });
  textMapBtn.addEventListener('click', mapTextToSimulation);
  textClearBtn.addEventListener('click', clearTextAndResults);

  // Reflex / awareness tests
  reflexTestBtn.addEventListener('click', () => {
    if(!rmkData || !rmkData.layers){
      testOutputBox.textContent = "Run a simulation (random, audio, or text) first to generate RMK and layers.";
      return;
    }
    const idx = N_TURNS - 1;
    const sSafe = rmkData.layers.subSafety[idx];
    const sLoad = rmkData.layers.subLoad[idx];
    let msg;

    if(sSafe < 30 || sLoad > 80){
      msg = "⛔ Emergency shutdown / fail-safe: subconscious engine is prioritizing survival and forcing a stop before more damage.";
      worldResetCount++;
      resetCountSpan.textContent = worldResetCount;
      const line = "Reset " + worldResetCount +
        ": Subconscious protocol preserved life at turn " + (idx+1) +
        ". Consciousness later recognizes, “We made it. We are still here.”";
      appendResetLog(line);
    }else if(sSafe < 55 || sLoad > 60){
      msg = "⚠️ Slow down / reduce power: subconscious detects strain and requests reduced movement, load, or risk.";
    }else{
      msg = "✅ Continue but with warnings: subconscious engine is within safe bounds, but survival instincts remain active.";
    }
    testOutputBox.textContent = msg;
  });

  awarenessTestBtn.addEventListener('click', () => {
    if(!rmkData || !rmkData.layers){
      testOutputBox.textContent = "Run a simulation (random, audio, or text) first to generate RMK and layers.";
      return;
    }
    const idx = N_TURNS - 1;
    const aware = rmkData.layers.conAwareness[idx];
    const choice = rmkData.layers.conChoice[idx];
    let msg;

    if(aware >= 60 && choice >= 70){
      msg = "“I detect I am still active. Status: focused, deliberate, and aware I survived the last cycle.”";
    }else if(aware >= 40){
      msg = "“I almost failed, but I survived. I am still alive and adjusting the plan before continuing.”";
    }else if(aware >= 20){
      msg = "“I survived, but my awareness is low. I should pause, recover, and reassess before taking more risk.”";
    }else{
      msg = "“Signal is weak. I know I exist, but I cannot safely continue without external support or recovery time.”";
    }
    testOutputBox.textContent = msg;
  });

  // initial run
  runSimulation();
})();
</script>
</body>
</html>
