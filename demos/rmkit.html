<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>RMK — Conscious & Subconscious Evaluation (Profile + Text + Video)</title>
<style>
  :root{
    --bg:#0b1222;
    --panel:#121a33;
    --ink:#edf2ff;
    --muted:#a9b7e3;
    --accent:#8fb4ff;
    --good:#7bffb1;
    --warn:#ffd37a;
    --bad:#ff8c8c;
    --grid:#1b2550;
  }
  *{box-sizing:border-box}
  body{
    margin:0;
    background:var(--bg);
    color:var(--ink);
    font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;
  }
  .wrap{
    max-width:1100px;
    margin:0 auto;
    padding:16px;
  }
  h1{
    margin:4px 0 8px;
    font-size:1.6rem;
  }
  h2{
    margin:12px 0 4px;
    font-size:1.2rem;
    color:var(--accent);
  }
  h3{
    margin:4px 0 4px;
    font-size:1rem;
  }
  .panel{
    background:var(--panel);
    border-radius:10px;
    padding:12px 14px;
    box-shadow:0 0 0 1px rgba(0,0,0,.4);
    margin-bottom:16px;
  }
  .controls{
    display:flex;
    flex-wrap:wrap;
    gap:8px;
    align-items:center;
    font-size:.9rem;
  }
  button{
    border:none;
    border-radius:999px;
    padding:6px 14px;
    background:var(--accent);
    color:#020617;
    font-weight:600;
    cursor:pointer;
  }
  button:hover{
    filter:brightness(1.1);
  }
  canvas{
    width:100%;
    max-width:100%;
    border-radius:8px;
    background:#050816;
    display:block;
  }
  .legend{
    display:flex;
    flex-wrap:wrap;
    gap:10px;
    font-size:.8rem;
    color:var(--muted);
    margin-top:6px;
  }
  .pill{
    display:inline-flex;
    align-items:center;
    gap:4px;
    padding:2px 8px;
    border-radius:999px;
    background:#0d1733;
  }
  .dot{
    width:8px;
    height:8px;
    border-radius:50%;
    background:var(--accent);
  }
  .dot.thetaC{background:var(--good);}
  .dot.thetaS{background:var(--warn);}
  .dot.emergeC{background:var(--good);}
  .dot.emergeS{background:var(--bad);}
  .summary{
    font-size:.88rem;
    color:var(--muted);
  }
  .summary.small{
    font-size:.78rem;
  }
  table{
    width:100%;
    border-collapse:collapse;
    font-size:.78rem;
    margin-top:8px;
  }
  th,td{
    padding:4px 6px;
    text-align:right;
    border-bottom:1px solid rgba(255,255,255,.04);
  }
  th{
    text-align:center;
    color:var(--muted);
    background:#0d1733;
    position:sticky;
    top:0;
    z-index:1;
  }
  td.turn{
    text-align:center;
    color:var(--accent);
  }
  tr.emergeC{
    background:rgba(123,255,177,0.18);
    animation: blinkC 1s infinite alternate;
  }
  tr.emergeS{
    background:rgba(255,140,140,0.18);
    animation: blinkS 1s infinite alternate;
  }
  .scroll{
    max-height:260px;
    overflow:auto;
    border-radius:8px;
    border:1px solid #141b33;
  }
  code{
    background:#020617;
    padding:2px 4px;
    border-radius:4px;
    font-size:.8rem;
  }

  .layers-grid{
    display:flex;
    flex-wrap:wrap;
    gap:10px;
    margin-top:8px;
  }
  .layer-card{
    flex:1 1 230px;
    background:#0d1733;
    border-radius:8px;
    padding:8px 10px;
  }
  .status-line{
    font-size:.85rem;
    margin:4px 0;
  }
  .status-line span{
    color:var(--good);
  }
  .scroll.mini{
    max-height:120px;
    overflow:auto;
    margin-top:6px;
    font-size:.78rem;
    background:#020617;
    border-radius:6px;
    padding:6px;
    border:1px solid #141b33;
  }

  .field-row{
    display:flex;
    flex-wrap:wrap;
    gap:8px;
    margin:4px 0;
    font-size:.86rem;
  }
  .field-row label{
    display:flex;
    flex-direction:column;
    gap:2px;
    flex:1 1 120px;
  }
  .field-row input,
  .field-row select{
    border-radius:999px;
    border:1px solid #141b33;
    padding:4px 8px;
    background:#020617;
    color:var(--ink);
    font-size:.84rem;
  }

  textarea{
    width:100%;
    min-height:120px;
    resize:vertical;
    border-radius:8px;
    border:1px solid #141b33;
    padding:8px;
    background:#020617;
    color:var(--ink);
    font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;
    font-size:.86rem;
  }

  @keyframes blinkC{
    from { background:rgba(123,255,177,0.18); }
    to   { background:rgba(123,255,177,0.45); }
  }
  @keyframes blinkS{
    from { background:rgba(255,140,140,0.18); }
    to   { background:rgba(255,140,140,0.45); }
  }

  @media print{
    body{
      background:#ffffff;
    }
    .panel{
      box-shadow:none;
      border-radius:0;
    }
    button{
      display:none;
    }
    tr.emergeC, tr.emergeS{
      animation:none;
    }
  }
</style>
</head>
<body>
<div class="wrap">
  <!-- MAIN HEADER -->
  <div class="panel">
    <h1>RMK — Conscious &amp; Subconscious Evaluation</h1>
    <p class="summary">
      This upgraded RMK simulation combines three layers:
      <strong>(1)</strong> your <em>profile + season + time-zone</em>,
      <strong>(2)</strong> a typed <em>100-word paragraph</em> (Conscious Captain),
      and <strong>(3)</strong> a <em>2-minute video</em> of you reading that same paragraph
      (Subconscious Engine leak: voice + face).
      It outputs <strong>ConsciousPerformance</strong>,
      <strong>SubconsciousStability</strong>,
      <strong>CouplingStrength</strong>,
      and two Theta timelines: Θ<sub>conscious</sub> and Θ<sub>subconscious</sub>.
      This is a research-style simulator only, not a medical tool or GCS replacement.
    </p>
    <div class="controls">
      <button id="runFromInputsBtn">Run Simulation from Profile + Text + Video</button>
      <button id="runRandomBtn">Run Random Baseline (no user data)</button>
      <button id="resetAllBtn">Clear / Reset All</button>
      <button id="printBtn">Print All</button>
      <button id="downloadSimCSVBtn">Download Simulation Metrics (CSV)</button>
      <button id="downloadPNG_Conscious">Download Θ<sub>conscious</sub> PNG</button>
      <button id="downloadPNG_Subcon">Download Θ<sub>subconscious</sub> PNG</button>
      <span class="summary small">Turns: <strong>40</strong> · Axis: 0 → 1 ordered state</span>
    </div>
  </div>

  <!-- PROFILE + SEASON + TIME-ZONE PANEL -->
  <div class="panel">
    <h2>Profile, Season &amp; Time-Zone Module</h2>
    <p class="summary small">
      Enter basic information so the simulator can estimate <em>seasonFactor</em>, <em>entrainmentMismatch</em>,
      and baseline <em>alertnessAmplitude</em> and <em>subconsciousNoise</em>.
      Day length and circadian alignment modify both layers.
    </p>

    <div class="field-row">
      <label>
        Age (years)
        <input type="number" id="ageInput" min="8" max="100" value="50" />
      </label>
      <label>
        City
        <input type="text" id="cityInput" placeholder="San Antonio" />
      </label>
      <label>
        State / Region
        <input type="text" id="stateInput" placeholder="TX" />
      </label>
    </div>

    <div class="field-row">
      <label>
        Hemisphere
        <select id="hemisphereSelect">
          <option value="N">Northern</option>
          <option value="S">Southern</option>
        </select>
      </label>
      <label>
        Simulated Month (1–12)
        <input type="number" id="monthInput" min="1" max="12" value="6" />
      </label>
      <label>
        Local Time Zone (label)
        <input type="text" id="tzLabelInput" placeholder="America/Chicago" />
      </label>
    </div>

    <div class="field-row">
      <label>
        Simulated Hour of Day (0–23)
        <input type="number" id="hourInput" min="0" max="23" value="10" />
      </label>
      <label>
        Preferred Sleep Midpoint (0–23)
        <input type="number" id="midSleepInput" min="0" max="23" value="2" />
      </label>
      <label>
        Export Profile as CSV
        <button id="downloadProfileCSVBtn" type="button">Download Profile CSV</button>
      </label>
    </div>

    <div class="controls" style="margin-top:6px;">
      <button id="computeEnvBtn">Compute Season &amp; Entrainment</button>
      <span class="summary small" id="envSummary">
        No environment computed yet.
      </span>
    </div>
  </div>

  <!-- TEXT PANEL: TYPED PARAGRAPH (CONSCIOUS CAPTAIN) -->
  <div class="panel">
    <h2>Typed Paragraph (≥ 100 words) → Conscious Captain Features</h2>
    <p class="summary small">
      Type or paste a paragraph of at least <strong>100 words</strong>.
      This samples <em>conscious, deliberate</em> thinking:
      word choice, structure, logic and openness.
      The simulation maps it to a 27-emotion vector and a 40-step 0/1 pattern.
    </p>
    <textarea id="textParagraph" placeholder="Type or paste at least 100 words here..."></textarea>
    <div class="controls" style="margin-top:6px;">
      <button id="textAnalyzeBtn">1. Analyze Text → 27 Emotions + Bits</button>
      <button id="textExportBtn">2. Download Text Analysis (CSV)</button>
      <button id="textLoadBtn">3. Upload Text Analysis (CSV)</button>
      <button id="textClearBtn">Clear Text &amp; Results</button>
      <input type="file" id="textAnalysisFileInput" accept=".csv,text/csv" style="display:none" />
    </div>
    <p class="text-meta summary small" id="textStatus">
      No paragraph analyzed yet.
    </p>
    <div class="scroll mini" id="textBitsBox">
      <!-- Bit-stream and 27-emotion snapshot for text appear here -->
    </div>
  </div>

  <!-- VIDEO PANEL: 2-MIN READING (VOICE + FACE) → SUBCONSCIOUS ENGINE -->
  <div class="panel">
    <h2>2-minute Video Reading → Subconscious Engine (Voice + Face)</h2>
    <p class="summary small">
      Record or upload a short video (around <strong>2 minutes</strong>) of you reading the
      <em>same paragraph</em> out loud. This panel uses a toy model to simulate:
      <strong>voice arousal</strong>, <strong>facial tension</strong>, and another 27-emotion vector
      that leaks subconscious patterns into the RMK engine (stress, fatigue, micro-expressions).
      In a real lab, this would use proper audio &amp; vision models; here it is a structured simulator.
    </p>
    <div class="controls">
      <button id="videoUploadBtn">Upload Video (MP4/WebM)</button>
      <button id="videoAnalyzeBtn">Analyze Video → Emotions + Bits (Simulated)</button>
      <button id="videoExportBtn">Download Video Analysis (CSV)</button>
      <button id="videoLoadBtn">Upload Video Analysis (CSV)</button>
      <button id="videoClearBtn">Clear Video &amp; Results</button>
      <input type="file" id="videoFileInput" accept="video/mp4,video/webm" style="display:none" />
      <input type="file" id="videoAnalysisFileInput" accept=".csv,text/csv" style="display:none" />
    </div>
    <p class="summary small" id="videoStatus">
      No video loaded yet.
    </p>
    <div class="scroll mini" id="videoBitsBox">
      <!-- Bit-stream and 27-emotion snapshot for video appear here -->
    </div>
  </div>
  <!-- THETA TIMELINES -->
  <div class="panel">
    <h2>Theta Timelines — Conscious vs Subconscious Layers</h2>
    <p class="summary small">
      These two lines show the evolution of <strong>Θ<sub>conscious</sub></strong>
      (Conscious Captain performance) and <strong>Θ<sub>subconscious</sub></strong>
      (Subconscious Engine stability) over 40 turns. Blinking highlights indicate
      emergence peaks above each layer’s recent baseline.
    </p>

    <h3>Θ<sub>conscious</sub> — Conscious Captain</h3>
    <canvas id="thetaCanvasConscious" width="1000" height="220"></canvas>

    <h3 style="margin-top:10px;">Θ<sub>subconscious</sub> — Subconscious Engine</h3>
    <canvas id="thetaCanvasSubcon" width="1000" height="220"></canvas>

    <div class="legend">
      <span class="pill"><span class="dot thetaC"></span> Θ<sub>conscious</sub> (ordered deliberate layer)</span>
      <span class="pill"><span class="dot thetaS"></span> Θ<sub>subconscious</sub> (ordered survival/background layer)</span>
      <span class="pill"><span class="dot emergeC"></span> Conscious emergence peak</span>
      <span class="pill"><span class="dot emergeS"></span> Subconscious emergence peak</span>
    </div>
  </div>

  <!-- TURN-BY-TURN METRICS TABLE -->
  <div class="panel">
    <h2>Turn-by-Turn Metrics (40 Steps)</h2>
    <p class="summary small">
      Each row represents one simulated step. Values are normalized (0–1). CouplingStrength mixes both layers.
      High Θ<sub>conscious</sub> with high CouplingStrength means strong, well-aligned deliberate performance.
      High Θ<sub>subconscious</sub> means a stable survival/background engine (not flooded by noise).
    </p>
    <div class="scroll">
      <table id="metricsTable">
        <thead>
          <tr>
            <th>t</th>
            <th>ConsciousPerformanceₜ</th>
            <th>SubconsciousStabilityₜ</th>
            <th>CouplingStrengthₜ</th>
            <th>Θ<sub>conscious</sub>ₜ</th>
            <th>Θ<sub>subconscious</sub>ₜ</th>
            <th>z(Θ<sub>conscious</sub>)</th>
            <th>z(Θ<sub>subconscious</sub>)</th>
            <th>Emergence Tag</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </div>

  <!-- CONSCIOUS / SUBCONSCIOUS SUMMARY + TESTS -->
  <div class="panel">
    <h2>Conscious Captain &amp; Subconscious Engine — Status &amp; Tests</h2>
    <p class="summary">
      This panel summarizes both layers for the <strong>latest turn</strong> and lets you run
      a quick <em>reflex</em> (subconscious) and <em>self-awareness</em> (conscious) test.
      It is a <strong>simulation</strong>, not a medical Glasgow Coma Scale or AVPU replacement.
    </p>
    <div class="layers-grid">
      <div class="layer-card">
        <h3>Subconscious Engine (Automatic Layer)</h3>
        <p class="summary small">
          Handles survival reflexes, background pattern checks, and safety limits. High stability and low overload
          mean the engine can protect the system without shutting everything down.
        </p>
        <p class="status-line">
          <strong>Subconscious status:</strong>
          <span id="subStatusText">—</span>
        </p>
        <p class="summary small">
          Safety: <span id="subSafetyVal">—</span> / 100
          · Load: <span id="subLoadVal">—</span> / 100
        </p>
      </div>
      <div class="layer-card">
        <h3>Conscious Captain (Deliberate Layer)</h3>
        <p class="summary small">
          Handles self-report, choices, planning and meaning-making. High awareness and good choices indicate the
          Captain can read the situation and decide what to do next.
        </p>
        <p class="status-line">
          <strong>Conscious status:</strong>
          <span id="conStatusText">—</span>
        </p>
        <p class="summary small">
          Awareness: <span id="conAwarenessVal">—</span> / 100
          · Choice Index: <span id="conChoiceVal">—</span> / 100
        </p>
      </div>
    </div>

    <div class="controls" style="margin-top:8px;">
      <button id="reflexTestBtn">Reflex / Survival Test (Subconscious)</button>
      <button id="awarenessTestBtn">Self-Awareness Test (Conscious)</button>
      <span class="summary small">
        <strong>World Reset Index:</strong> <span id="resetCount">0</span>
      </span>
    </div>

    <div class="scroll mini" id="resetLogBox">
      <!-- Reset-log lines appear here -->
    </div>

    <p class="summary small" id="testOutputBox" style="margin-top:6px;">
      <!-- Test messages appear here -->
    </p>

    <p class="summary small" style="margin-top:6px;">
      In your theory, <strong>consciousness</strong> is the baseline “I exist” signal.
      This simulator watches how that baseline behaves under different loads:
      the Subconscious Engine can force survival resets, and the Conscious Captain
      can notice, explain, and adapt.
    </p>
  </div>

  <!-- EXPLANATION PANEL -->
  <div class="panel">
    <h2>How This Differs from Glasgow Coma Scale / AVPU</h2>
    <p class="summary">
      Clinical tools like the <strong>Glasgow Coma Scale (GCS)</strong> and <strong>AVPU</strong> ask:
      “Is this person awake, responsive, and oriented right now?” They are used in trauma and critical care,
      and they measure level of responsiveness—eye opening, verbal response, motor response, and basic orientation
      (person, place, time, event).
    </p>
    <p class="summary">
      Your <strong>RMK Conscious/Subconscious Simulator</strong> asks a different question:
      “Given the person is awake enough to type, speak, and appear on camera, how are the <em>two layers</em>
      behaving?”
      The <em>typed paragraph</em> probes the <strong>Conscious Captain</strong>, and the
      <em>video reading</em> leaks information from the <strong>Subconscious Engine</strong>
      (voice, micro-expressions, fatigue).
      Day length, age, and circadian alignment tilt both layers up or down.
    </p>
    <p class="summary">
      The outputs — <strong>ConsciousPerformance</strong>,
      <strong>SubconsciousStability</strong>,
      <strong>CouplingStrength</strong>,
      Θ<sub>conscious</sub> and Θ<sub>subconscious</sub> — are therefore
      <em>development-science metrics</em>, not medical clearance.
      They help visualize how consciousness and subconscious survival loads interact under your cosmic-clock
      and RMK framework.
    </p>
  </div>
</div>
<script>
(function(){
  const N_TURNS = 40;
  const BASELINE_WINDOW = 8;
  const Z_THRESHOLD = 1.8;

  const EMOTION_NAMES = [
    "admiration","adoration","aesthetic_appreciation","amusement","anger","anxiety",
    "awe","awkwardness","boredom","calmness","confusion","craving","disgust",
    "empathic_pain","entrancement","envy","excitement","fear","horror","interest",
    "joy","nostalgia","romance","sadness","satisfaction","sexual_desire","surprise"
  ];

  /* ---------- DOM HOOKS ---------- */
  const runFromInputsBtn   = document.getElementById('runFromInputsBtn');
  const runRandomBtn       = document.getElementById('runRandomBtn');
  const resetAllBtn        = document.getElementById('resetAllBtn');
  const printBtn           = document.getElementById('printBtn');
  const downloadSimCSVBtn  = document.getElementById('downloadSimCSVBtn');
  const downloadPNG_Con    = document.getElementById('downloadPNG_Conscious');
  const downloadPNG_Sub    = document.getElementById('downloadPNG_Subcon');

  /* Profile / Environment */
  const ageInput           = document.getElementById('ageInput');
  const cityInput          = document.getElementById('cityInput');
  const stateInput         = document.getElementById('stateInput');
  const hemisphereSelect   = document.getElementById('hemisphereSelect');
  const monthInput         = document.getElementById('monthInput');
  const tzLabelInput       = document.getElementById('tzLabelInput');
  const hourInput          = document.getElementById('hourInput');
  const midSleepInput      = document.getElementById('midSleepInput');
  const computeEnvBtn      = document.getElementById('computeEnvBtn');
  const envSummary         = document.getElementById('envSummary');
  const downloadProfileCSVBtn = document.getElementById('downloadProfileCSVBtn');

  /* Text analysis */
  const textParagraph      = document.getElementById('textParagraph');
  const textAnalyzeBtn     = document.getElementById('textAnalyzeBtn');
  const textExportBtn      = document.getElementById('textExportBtn');
  const textLoadBtn        = document.getElementById('textLoadBtn');
  const textClearBtn       = document.getElementById('textClearBtn');
  const textAnalysisFileInput = document.getElementById('textAnalysisFileInput');
  const textStatus         = document.getElementById('textStatus');
  const textBitsBox        = document.getElementById('textBitsBox');

  /* Video analysis */
  const videoUploadBtn     = document.getElementById('videoUploadBtn');
  const videoAnalyzeBtn    = document.getElementById('videoAnalyzeBtn');
  const videoExportBtn     = document.getElementById('videoExportBtn');
  const videoLoadBtn       = document.getElementById('videoLoadBtn');
  const videoClearBtn      = document.getElementById('videoClearBtn');
  const videoFileInput     = document.getElementById('videoFileInput');
  const videoAnalysisFileInput = document.getElementById('videoAnalysisFileInput');
  const videoStatus        = document.getElementById('videoStatus');
  const videoBitsBox       = document.getElementById('videoBitsBox');

  /* Theta canvases + table */
  const canvasCon          = document.getElementById('thetaCanvasConscious');
  const ctxCon             = canvasCon.getContext('2d');
  const canvasSub          = document.getElementById('thetaCanvasSubcon');
  const ctxSub             = canvasSub.getContext('2d');
  const metricsTableBody   = document.querySelector('#metricsTable tbody');

  /* Layer summaries */
  const subStatusText      = document.getElementById('subStatusText');
  const subSafetyVal       = document.getElementById('subSafetyVal');
  const subLoadVal         = document.getElementById('subLoadVal');
  const conStatusText      = document.getElementById('conStatusText');
  const conAwarenessVal    = document.getElementById('conAwarenessVal');
  const conChoiceVal       = document.getElementById('conChoiceVal');
  const reflexTestBtn      = document.getElementById('reflexTestBtn');
  const awarenessTestBtn   = document.getElementById('awarenessTestBtn');
  const resetCountSpan     = document.getElementById('resetCount');
  const resetLogBox        = document.getElementById('resetLogBox');
  const testOutputBox      = document.getElementById('testOutputBox');

  /* State */
  let envProfile = null;          // {ageYears, seasonFactor, dayLength, entrainmentMismatch, alertnessAmplitude, subconsciousNoiseBase, topDownControlBase}
  let textAnalysis = null;        // {bits, emotions, dominant, wordCount}
  let videoAnalysis = null;       // {bits, emotions, dominant, voiceArousal, facialTension}
  let simData = null;             // {conPerf, subStab, coupling, thetaC, thetaS, zC, zS, flagsC, flagsS}
  let worldResetCount = 0;

  let chartCon = null;            // for animation
  let chartSub = null;

  /* ---------- Utility ---------- */
  function clamp01(x){ return Math.max(0, Math.min(1, x)); }

  function makePRNG(seedStr){
    let h = 2166136261 >>> 0;
    for(let i=0;i<seedStr.length;i++){
      h ^= seedStr.charCodeAt(i);
      h = Math.imul(h, 16777619);
    }
    return function(){
      h = (h + 0x6D2B79F5) | 0;
      let t = Math.imul(h ^ (h >>> 15), 1 | h);
      t = t + Math.imul(t ^ (t >>> 7), 61 | t) ^ t;
      return ((t ^ (t >>> 14)) >>> 0) / 4294967296;
    };
  }

  function rollingStats(arr, win){
    const mean = new Array(arr.length).fill(null);
    const std  = new Array(arr.length).fill(null);
    for(let i=0;i<arr.length;i++){
      const start = Math.max(0, i-win+1);
      const slice = arr.slice(start, i+1);
      const m = slice.reduce((s,v)=>s+v,0) / slice.length;
      const v = slice.reduce((s,v)=>s+(v-m)*(v-m),0) / slice.length;
      mean[i] = m;
      std[i]  = Math.sqrt(v) || 0.0001;
    }
    return {mean,std};
  }

  function detectEmergence(Theta){
    const {mean,std} = rollingStats(Theta, BASELINE_WINDOW);
    const z = [];
    const flags = [];
    for(let i=0;i<Theta.length;i++){
      const zi = (Theta[i] - mean[i]) / std[i];
      z.push(zi);
      flags.push(zi > Z_THRESHOLD);
    }
    return {z,flags};
  }

  function downloadTextFile(filename, text, mime){
    const blob = new Blob([text], {type: mime || "text/plain"});
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  }

  function downloadCanvasPNG(canvas, filename){
    const link = document.createElement('a');
    link.href = canvas.toDataURL('image/png');
    link.download = filename;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
  }

  function appendResetLog(line){
    const div = document.createElement('div');
    div.textContent = line;
    resetLogBox.appendChild(div);
    resetLogBox.scrollTop = resetLogBox.scrollHeight;
  }

  /* ---------- ENVIRONMENT / PROFILE MODULE ---------- */
  function computeEnvironment(){
    const ageYears = parseFloat(ageInput.value) || 50;
    const hem = hemisphereSelect.value || "N";
    const month = Math.max(1, Math.min(12, parseInt(monthInput.value || "6",10)));
    const hour = Math.max(0, Math.min(23, parseInt(hourInput.value || "10",10)));
    const midSleep = Math.max(0, Math.min(23, parseInt(midSleepInput.value || "2",10)));

    // Simple cos model for day length (approx 8–16 hours)
    const phase = (month - 1) / 12 * 2*Math.PI;
    let dayLength = 12 + 4*Math.cos(phase);
    if(hem === "S") dayLength = 12 - (dayLength - 12); // invert seasons

    dayLength = Math.max(8, Math.min(16, dayLength));
    const seasonFactor = (dayLength - 8) / (16 - 8);  // 0 = short-day winter, 1 = long-day summer

    // Age factor (0 at 20, 1 at 80+)
    const ageNorm = clamp01((ageYears - 20) / 60);

    // Entrainment mismatch: distance between current hour and preferred sleep midpoint
    let diff = Math.abs(hour - midSleep);
    if(diff > 12) diff = 24 - diff;
    const entrainmentMismatch = clamp01(diff / 12); // 0 aligned, 1 very misaligned

    // Alertness amplitude rises with long days, falls with age and mismatch
    const baseAlert = 0.4 + 0.6*seasonFactor;
    const alertnessAmplitude = clamp01(baseAlert * (1 - 0.3*ageNorm) * (1 - 0.4*entrainmentMismatch));

    // Subconscious noise increases with age and mismatch, slightly with short days
    const subconsciousNoiseBase = clamp01(0.2 + 0.3*ageNorm + 0.3*entrainmentMismatch + 0.2*(1 - seasonFactor));

    // Top-down control baseline: declines with age and high mismatch
    const topDownControlBase = clamp01(0.8 - 0.3*ageNorm - 0.2*entrainmentMismatch);

    envProfile = {
      ageYears,
      hemisphere: hem,
      month,
      hour,
      midSleep,
      dayLength,
      seasonFactor,
      entrainmentMismatch,
      alertnessAmplitude,
      subconsciousNoiseBase,
      topDownControlBase,
      city: cityInput.value || "",
      state: stateInput.value || "",
      tzLabel: tzLabelInput.value || ""
    };

    envSummary.textContent =
      "SeasonFactor: " + seasonFactor.toFixed(2) +
      " · Day length ≈ " + dayLength.toFixed(1) + " h" +
      " · EntrainmentMismatch: " + entrainmentMismatch.toFixed(2) +
      " · AlertnessAmplitude: " + alertnessAmplitude.toFixed(2) +
      " · SubconsciousNoise (base): " + subconsciousNoiseBase.toFixed(2);
  }

  function buildProfileCSV(){
    if(!envProfile){
      return "No profile computed yet.";
    }
    const p = envProfile;
    const header = [
      "ageYears","city","state","hemisphere","month","hour","midSleep",
      "tzLabel","dayLength","seasonFactor","entrainmentMismatch",
      "alertnessAmplitude","subconsciousNoiseBase","topDownControlBase"
    ];
    const row = [
      p.ageYears,
      JSON.stringify(p.city),
      JSON.stringify(p.state),
      p.hemisphere,
      p.month,
      p.hour,
      p.midSleep,
      JSON.stringify(p.tzLabel),
      p.dayLength.toFixed(3),
      p.seasonFactor.toFixed(3),
      p.entrainmentMismatch.toFixed(3),
      p.alertnessAmplitude.toFixed(3),
      p.subconsciousNoiseBase.toFixed(3),
      p.topDownControlBase.toFixed(3)
    ];
    return header.join(",") + "\n" + row.join(",");
  }

  /* ---------- TEXT ANALYSIS (CONSCIOUS) ---------- */
  const emotionKeywordMap = {
    joy: ["happy","glad","joy","smile","laugh","delight"],
    sadness: ["sad","cry","lonely","grief","loss","tear"],
    anger: ["angry","mad","furious","rage","irritated","annoyed"],
    fear: ["afraid","fear","scared","terrified","panic"],
    anxiety: ["anxious","nervous","worried","uneasy","tension"],
    calmness: ["calm","peaceful","relaxed","serene","quiet"],
    admiration: ["admire","respect","inspired","hero"],
    adoration: ["love","adore","beloved","precious"],
    awe: ["awe","astonished","overwhelmed","majestic"],
    amusement: ["funny","amusing","joke","humor"],
    boredom: ["bored","dull","boring","monotony"],
    disgust: ["disgust","gross","nausea","revolting"],
    surprise: ["surprised","shock","unexpected","suddenly"],
    nostalgia: ["nostalgia","memory","remember","childhood","past"],
    romance: ["romantic","kiss","embrace","date","lover"],
    satisfaction: ["satisfied","content","fulfilled","accomplished"],
    craving: ["craving","want","desire","need","yearn"],
    sexual_desire: ["sexual","desire","lust","intimate"],
    interest: ["curious","interested","engaged","fascinated"],
    excitement: ["excited","thrilled","eager","energetic"],
    horror: ["horror","nightmare","ghastly","gory"],
    confusion: ["confused","unclear","lost","puzzled"],
    awkwardness: ["awkward","embarrassed","clumsy"],
    envy: ["envy","jealous","resent"],
    empathic_pain: ["sorry","hurt","pain","suffer"],
    entrancement: ["entranced","spellbound","mesmerized","hypnotic"]
  };

  function analyzeTextParagraph(){
    const text = textParagraph.value || "";
    const words = text.toLowerCase().match(/\b[a-z]+\b/g) || [];
    const wordCount = words.length;

    if(wordCount < 100){
      textStatus.textContent =
        "Warning: paragraph has only " + wordCount + " words (recommended ≥ 100). Analysis will still run.";
    }else{
      textStatus.textContent =
        "Paragraph length: " + wordCount + " words. Analyzing patterns (toy model)...";
    }

    const seedStr = text.slice(0,256);
    const rand = makePRNG(seedStr || "default-text-seed");

    const emotions = {};
    EMOTION_NAMES.forEach(name => {
      let base = 0.2 + 0.4*rand();
      const kwList = emotionKeywordMap[name] || [];
      if(kwList.length > 0 && wordCount > 0){
        let count = 0;
        for(const w of words){
          for(const kw of kwList){
            if(w === kw){
              count++;
            }
          }
        }
        const bump = Math.min(0.6, count * 0.03);
        base += bump;
      }
      emotions[name] = clamp01(base);
    });

    let dominant = EMOTION_NAMES[0];
    let maxVal = -1;
    for(const k of EMOTION_NAMES){
      if(emotions[k] > maxVal){
        maxVal = emotions[k];
        dominant = k;
      }
    }

    const bits = [];
    for(let i=0;i<N_TURNS;i++){
      bits.push(rand() > 0.5 ? 1 : 0);
    }

    textAnalysis = {
      bits,
      emotions,
      dominant,
      wordCount
    };

    const emoLines = EMOTION_NAMES
      .map(k => k + ": " + emotions[k].toFixed(2))
      .join(" · ");
    const bitLine = bits.map((b,i)=>((i+1)+":"+b)).join("  ");

    textBitsBox.textContent =
      "Bit-stream (40 turns, derived from text):\n" +
      bitLine +
      "\n\n27 emotion scores (0–1, keyword+noise model):\n" +
      emoLines;
  }

  function buildAnalysisCSV(analysis, typeLabel){
    const header = ["type","bits"].concat(EMOTION_NAMES).concat(["dominant"]);
    const bitsStr = (analysis.bits || []).map(b=>b?"1":"0").join("");
    const row = [typeLabel, bitsStr];
    EMOTION_NAMES.forEach(name=>{
      const v = analysis.emotions && analysis.emotions[name]!=null ? analysis.emotions[name] : 0;
      row.push(v.toFixed(4));
    });
    row.push(analysis.dominant || "");
    return header.join(",") + "\n" + row.join(",");
  }

  function parseAnalysisCSV(csvText){
    const lines = csvText.trim().split(/\r?\n/);
    if(lines.length < 2) throw new Error("CSV must have at least 2 lines");
    const header = lines[0].split(",");
    const cols   = lines[1].split(",");
    const idxBits = header.indexOf("bits");
    if(idxBits === -1) throw new Error("CSV missing 'bits' column");
    const bitsStr = cols[idxBits] || "";
    const bits = bitsStr.split("").slice(0,N_TURNS).map(c => c==="1" ? 1 : 0);

    const emotions = {};
    EMOTION_NAMES.forEach(name=>{
      const idx = header.indexOf(name);
      if(idx !== -1 && cols[idx] !== undefined){
        const val = parseFloat(cols[idx]);
        emotions[name] = isNaN(val)?0:val;
      }else{
        emotions[name] = 0;
      }
    });

    const idxDom = header.indexOf("dominant");
    const dominant = idxDom !== -1 ? (cols[idxDom] || "") : "";

    return {bits, emotions, dominant};
  }

  /* ---------- VIDEO ANALYSIS (SUBCONSCIOUS) ---------- */
  function analyzeVideoFile(file){
    // PRNG based on file metadata to keep it deterministic for the same file
    const seedStr = file.name + ":" + file.size + ":" + file.lastModified;
    const rand = makePRNG(seedStr);

    const bits = [];
    for(let i=0;i<N_TURNS;i++){
      bits.push(rand() > 0.5 ? 1 : 0);
    }

    const emotions = {};
    EMOTION_NAMES.forEach(name=>{
      emotions[name] = clamp01(0.2 + 0.6*rand());
    });

    // Voice arousal + facial tension as separate top features
    const voiceArousal   = clamp01(0.3 + 0.7*rand());
    const facialTension  = clamp01(0.3 + 0.7*rand());

    let dominant = EMOTION_NAMES[0];
    let maxVal = -1;
    for(const k of EMOTION_NAMES){
      if(emotions[k] > maxVal){
        maxVal = emotions[k];
        dominant = k;
      }
    }

    videoAnalysis = {
      bits,
      emotions,
      dominant,
      voiceArousal,
      facialTension,
      fileName: file.name,
      fileSize: file.size
    };

    const emoLines = EMOTION_NAMES
      .map(k => k + ": " + emotions[k].toFixed(2))
      .join(" · ");
    const bitLine = bits.map((b,i)=>((i+1)+":"+b)).join("  ");

    videoStatus.textContent =
      "Video loaded: " + file.name +
      " (" + file.size + " bytes). Dominant (simulated) emotion: " + dominant +
      " · VoiceArousal: " + voiceArousal.toFixed(2) +
      " · FacialTension: " + facialTension.toFixed(2);

    videoBitsBox.textContent =
      "Bit-stream (40 turns, simulated from video):\n" +
      bitLine +
      "\n\n27 emotion scores (0–1, toy model):\n" +
      emoLines +
      "\n\nNote: In reality this would come from voice + face models. Here it is a structured simulator.";
  }

  function buildVideoCSV(){
    if(!videoAnalysis){
      return "No video analysis to export.";
    }
    const header = ["type","bits"].concat(EMOTION_NAMES).concat(["dominant","voiceArousal","facialTension"]);
    const bitsStr = (videoAnalysis.bits||[]).map(b=>b?"1":"0").join("");
    const row = ["video", bitsStr];
    EMOTION_NAMES.forEach(name=>{
      const v = videoAnalysis.emotions && videoAnalysis.emotions[name]!=null ? videoAnalysis.emotions[name] : 0;
      row.push(v.toFixed(4));
    });
    row.push(videoAnalysis.dominant || "");
    row.push(videoAnalysis.voiceArousal.toFixed(4));
    row.push(videoAnalysis.facialTension.toFixed(4));
    return header.join(",") + "\n" + row.join(",");
  }

  function parseVideoCSV(csvText){
    const lines = csvText.trim().split(/\r?\n/);
    if(lines.length < 2) throw new Error("CSV must have at least 2 lines");
    const header = lines[0].split(",");
    const cols   = lines[1].split(",");
    const idxBits = header.indexOf("bits");
    if(idxBits === -1) throw new Error("CSV missing 'bits' column");
    const bitsStr = cols[idxBits] || "";
    const bits = bitsStr.split("").slice(0,N_TURNS).map(c => c==="1" ? 1 : 0);

    const emotions = {};
    EMOTION_NAMES.forEach(name=>{
      const idx = header.indexOf(name);
      if(idx !== -1 && cols[idx] !== undefined){
        const val = parseFloat(cols[idx]);
        emotions[name] = isNaN(val)?0:val;
      }else{
        emotions[name] = 0;
      }
    });

    const idxDom = header.indexOf("dominant");
    const idxA   = header.indexOf("voiceArousal");
    const idxF   = header.indexOf("facialTension");
    const dominant = idxDom !== -1 ? (cols[idxDom] || "") : "";
    const voiceArousal  = idxA !== -1 ? (parseFloat(cols[idxA]) || 0.5) : 0.5;
    const facialTension = idxF !== -1 ? (parseFloat(cols[idxF]) || 0.5) : 0.5;

    return {bits, emotions, dominant, voiceArousal, facialTension};
  }

  /* ---------- HIGH-LEVEL METRICS FROM TEXT + VIDEO + ENV ---------- */
  function computeHighLevelScalars(){
    // Defaults if pieces are missing
    let conScalar = 0.6;
    let subScalar = 0.6;
    let couplingBase = 0.6;

    // 1) From text (conscious)
    if(textAnalysis){
      const emo = textAnalysis.emotions || {};
      const pos = Math.max(
        emo.joy || 0,
        emo.satisfaction || 0,
        emo.admiration || 0,
        emo.adoration || 0,
        emo.excitement || 0
      );
      const neg = Math.max(
        emo.fear || 0,
        emo.anxiety || 0,
        emo.sadness || 0,
        emo.anger || 0,
        emo.disgust || 0
      );
      const calm = emo.calmness || 0.5;
      const flex = (emo.interest || 0.5) + (emo.awe || 0) + (emo.nostalgia || 0);
      const flexNorm = clamp01(flex / 3);

      // conscious performance: positive balance, calm, and flexibility
      conScalar = clamp01(0.3 + 0.4*pos + 0.2*calm + 0.3*flexNorm - 0.3*neg);
    }

    // 2) From video (subconscious)
    let voiceA = 0.6, faceT = 0.6;
    if(videoAnalysis){
      voiceA = videoAnalysis.voiceArousal;
      faceT  = videoAnalysis.facialTension;
      const emoV = videoAnalysis.emotions || {};
      const calmV = emoV.calmness || 0.5;
      const fearV = emoV.fear || 0;
      const anxV  = emoV.anxiety || 0;
      const loadNeg = Math.max(fearV, anxV, faceT);

      // base stability: calm + moderate arousal – overload
      subScalar = clamp01(0.3 + 0.4*calmV + 0.2*(1 - loadNeg));
    }

    // 3) From environment
    let alertAmp = 0.7;
    let subNoise = 0.3;
    let topDownBase = 0.7;
    let mismatch = 0.3;
    if(envProfile){
      alertAmp   = envProfile.alertnessAmplitude;
      subNoise   = envProfile.subconsciousNoiseBase;
      topDownBase = envProfile.topDownControlBase;
      mismatch    = envProfile.entrainmentMismatch;
    }

    // 4) Combine into coupling strength
    const subconsciousNoise = clamp01(subNoise + 0.2*faceT);
    const topDownControlStrength = clamp01(topDownBase * (0.6 + 0.4*conScalar));

    const couplingStrength = clamp01(
      (topDownControlStrength * alertAmp) / (1 + subconsciousNoise)
    );

    // Subconscious stability also influenced by mismatch + noise
    subScalar = clamp01(
      subScalar * (1 - 0.4*mismatch) * (1 - 0.3*subconsciousNoise)
    );

    return {
      consciousPerformance: conScalar,
      subconsciousStability: subScalar,
      couplingStrength,
      alertnessAmplitude: alertAmp,
      subconsciousNoise,
      topDownControlStrength,
      entrainmentMismatch: mismatch
    };
  }

  function buildTimelinesFromScalars(h){
    // Build 40-turn curves with circadian-like modulation
    const conPerf = [];
    const subStab = [];
    const coupling = [];
    const thetaC = [];
    const thetaS = [];

    const baseC = h.consciousPerformance;
    const baseS = h.subconsciousStability;
    const baseCouple = h.couplingStrength;

    const TWO_PI = Math.PI*2;
    for(let t=0;t<N_TURNS;t++){
      const phase = TWO_PI * (t/(N_TURNS-1));
      const circadian = 0.8 + 0.2*Math.cos(phase - Math.PI/2); // mid-simulation "day"

      const jitterC = (Math.random()*0.08 - 0.04);
      const jitterS = (Math.random()*0.08 - 0.04);
      const jitterCouple = (Math.random()*0.06 - 0.03);

      const c = clamp01(baseC * circadian + jitterC);
      const s = clamp01(baseS * (0.9 + 0.1*Math.sin(phase)) + jitterS);
      const k = clamp01(baseCouple * (0.9 + 0.1*Math.cos(phase)) + jitterCouple);

      conPerf.push(c);
      subStab.push(s);
      coupling.push(k);

      const thetaCon = clamp01(c * k);
      const thetaSub = clamp01(s * (1 - h.entrainmentMismatch) * (1 - 0.4*h.subconsciousNoise));
      thetaC.push(thetaCon);
      thetaS.push(thetaSub);
    }

    const emC = detectEmergence(thetaC);
    const emS = detectEmergence(thetaS);

    const flagsC = emC.flags;
    const flagsS = emS.flags;

    return {
      conPerf,
      subStab,
      coupling,
      thetaC,
      thetaS,
      zC: emC.z,
      zS: emS.z,
      flagsC,
      flagsS
    };
  }

  /* ---------- TABLE + LAYER UI ---------- */
  function fillMetricsTable(data){
    metricsTableBody.innerHTML = "";
    for(let t=0;t<N_TURNS;t++){
      const tr = document.createElement('tr');

      if(data.flagsC[t]) tr.classList.add('emergeC');
      if(data.flagsS[t]) tr.classList.add('emergeS');

      const tdT = document.createElement('td');
      tdT.className = 'turn';
      tdT.textContent = t+1;
      tr.appendChild(tdT);

      function tdNum(v){
        const td = document.createElement('td');
        td.textContent = v.toFixed(3);
        return td;
      }

      tr.appendChild(tdNum(data.conPerf[t]));
      tr.appendChild(tdNum(data.subStab[t]));
      tr.appendChild(tdNum(data.coupling[t]));
      tr.appendChild(tdNum(data.thetaC[t]));
      tr.appendChild(tdNum(data.thetaS[t]));
      tr.appendChild(tdNum(data.zC[t]));
      tr.appendChild(tdNum(data.zS[t]));

      const tdTag = document.createElement('td');
      let tag = "";
      if(data.flagsC[t] && data.flagsS[t]){
        tag = "Joint emergence (C+S peak)";
      }else if(data.flagsC[t]){
        tag = "Conscious peak (insight / decision)";
      }else if(data.flagsS[t]){
        tag = "Subconscious peak (survival / reset)";
      }
      tdTag.textContent = tag;
      tr.appendChild(tdTag);

      metricsTableBody.appendChild(tr);
    }
  }

  function classifySubStatus(safety, load){
    if(safety >= 70 && load <= 40) return "Calm / Protected";
    if(safety >= 40 && load <= 70) return "Alert / Loaded";
    return "Overloaded / Shutdown-Tilt";
  }

  function classifyConStatus(awareness, choice){
    if(awareness < 30 && choice < 40) return "Distracted / Weak Signal";
    if(awareness >= 60 && choice >= 70) return "Focused / Deliberate";
    if(choice >= 85) return "Overriding Risk / Pushing Limits";
    if(awareness >= 40) return "Aware / Adjusting";
    return "Aware but Low Power";
  }

  function updateLayerUIFromSim(data){
    if(!data) return;
    const idx = N_TURNS - 1;
    const c = data.conPerf[idx];
    const s = data.subStab[idx];
    const k = data.coupling[idx];

    const safety = Math.round(100 * clamp01(s * (1 - data.flagsS[idx]*0.1)));
    const load   = Math.round(100 * clamp01(1 - s + (data.flagsS[idx]?0.2:0)));
    const aware  = Math.round(100 * c);
    const choice = Math.round(100 * k);

    subSafetyVal.textContent = safety;
    subLoadVal.textContent   = load;
    conAwarenessVal.textContent = aware;
    conChoiceVal.textContent    = choice;

    subStatusText.textContent = classifySubStatus(safety, load);
    conStatusText.textContent = classifyConStatus(aware, choice);
  }

  /* ---------- DRAWING ---------- */
  function drawThetaAnimated(ctx, canvas, Theta, flags, timeMs, colorBase){
    const w = canvas.width;
    const h = canvas.height;
    ctx.clearRect(0,0,w,h);

    ctx.fillStyle = "#020617";
    ctx.fillRect(0,0,w,h);

    ctx.strokeStyle = "rgba(255,255,255,0.06)";
    ctx.lineWidth = 1;
    for(let i=0;i<=4;i++){
      const y = h * i/4;
      ctx.beginPath();
      ctx.moveTo(0,y);
      ctx.lineTo(w,y);
      ctx.stroke();
    }

    ctx.fillStyle = "rgba(255,255,255,0.4)";
    ctx.font = "10px system-ui";
    ctx.fillText("Θ", 4, 10);
    ctx.fillText("0", 4, h-4);
    ctx.fillText("1.0", 4, 12);

    const maxTheta = Math.max(...Theta,1);
    const minTheta = Math.min(...Theta,0);

    function xPos(i){
      return (w-40) * (i/(Theta.length-1)) + 30;
    }
    function yPos(v){
      const norm = (v - minTheta) / ((maxTheta-minTheta)||1);
      return h - 20 - norm*(h-40);
    }

    ctx.strokeStyle = colorBase || "#7bffb1";
    ctx.lineWidth = 2;
    ctx.beginPath();
    for(let i=0;i<Theta.length;i++){
      const x = xPos(i);
      const y = yPos(Theta[i]);
      if(i===0) ctx.moveTo(x,y);
      else ctx.lineTo(x,y);
    }
    ctx.stroke();

    const phase = (Math.sin(timeMs/300) + 1)/2;

    for(let i=0;i<Theta.length;i++){
      if(flags[i]){
        const x = xPos(i);
        const y = yPos(Theta[i]);
        const radius = 3 + phase*3.5;
        const glowAlpha = 0.4 + phase*0.5;
        const grad = ctx.createRadialGradient(x,y,0,x,y,radius*2.4);
        grad.addColorStop(0, `rgba(255,255,200,${glowAlpha})`);
        grad.addColorStop(1, 'rgba(255,255,200,0)');
        ctx.fillStyle = grad;
        ctx.beginPath();
        ctx.arc(x,y,radius*2.4,0,Math.PI*2);
        ctx.fill();

        ctx.fillStyle = "#ffff9c";
        ctx.beginPath();
        ctx.arc(x,y,radius,0,Math.PI*2);
        ctx.fill();
      }
    }

    ctx.strokeStyle = "rgba(255,255,255,0.25)";
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(30,h-20);
    ctx.lineTo(w-10,h-20);
    ctx.stroke();

    ctx.fillStyle = "rgba(255,255,255,0.5)";
    ctx.fillText("turn", w-35,h-8);
  }

  function animationLoop(timestamp){
    if(chartCon){
      drawThetaAnimated(ctxCon, canvasCon, chartCon.Theta, chartCon.flags, timestamp, "#7bffb1");
    }
    if(chartSub){
      drawThetaAnimated(ctxSub, canvasSub, chartSub.Theta, chartSub.flags, timestamp, "#ffd37a");
    }
    requestAnimationFrame(animationLoop);
  }
  requestAnimationFrame(animationLoop);

  /* ---------- SIMULATION RUNNERS ---------- */
  function runSimulationFromInputs(){
    if(!envProfile){
      computeEnvironment();
    }
    const scalars = computeHighLevelScalars();
    const timelines = buildTimelinesFromScalars(scalars);
    simData = timelines;
    fillMetricsTable(timelines);

    chartCon = {Theta: timelines.thetaC, flags: timelines.flagsC};
    chartSub = {Theta: timelines.thetaS, flags: timelines.flagsS};

    updateLayerUIFromSim(timelines);
    testOutputBox.textContent =
      "Simulation based on current profile + text + video. ConsciousPerformance=" +
      scalars.consciousPerformance.toFixed(2) +
      ", SubconsciousStability=" +
      scalars.subconsciousStability.toFixed(2) +
      ", CouplingStrength=" +
      scalars.couplingStrength.toFixed(2) +
      ".";
  }

  function runRandomBaseline(){
    // Clear env/text/video, but keep explanation simple
    const rand = makePRNG("random-baseline");
    envProfile = null;
    textAnalysis = null;
    videoAnalysis = null;

    const scalars = {
      consciousPerformance: 0.4 + 0.4*rand(),
      subconsciousStability: 0.4 + 0.4*rand(),
      couplingStrength: 0.4 + 0.4*rand(),
      alertnessAmplitude: 0.6,
      subconsciousNoise: 0.3,
      topDownControlStrength: 0.6,
      entrainmentMismatch: 0.3
    };

    const timelines = buildTimelinesFromScalars(scalars);
    simData = timelines;
    fillMetricsTable(timelines);
    chartCon = {Theta: timelines.thetaC, flags: timelines.flagsC};
    chartSub = {Theta: timelines.thetaS, flags: timelines.flagsS};
    updateLayerUIFromSim(timelines);

    envSummary.textContent = "Random baseline: no real profile, text, or video used.";
    textStatus.textContent = "Random baseline: no text used.";
    videoStatus.textContent = "Random baseline: no video used.";
    testOutputBox.textContent =
      "Random baseline run: compare later against real profile + text + video runs.";
  }

  function resetAll(){
    envProfile = null;
    textAnalysis = null;
    videoAnalysis = null;
    simData = null;
    chartCon = null;
    chartSub = null;

    ctxCon.fillStyle = "#020617";
    ctxCon.fillRect(0,0,canvasCon.width,canvasCon.height);
    ctxSub.fillStyle = "#020617";
    ctxSub.fillRect(0,0,canvasSub.width,canvasSub.height);

    metricsTableBody.innerHTML = "";
    subStatusText.textContent = "—";
    subSafetyVal.textContent = "—";
    subLoadVal.textContent = "—";
    conStatusText.textContent = "—";
    conAwarenessVal.textContent = "—";
    conChoiceVal.textContent = "—";

    envSummary.textContent = "No environment computed yet.";
    textStatus.textContent = "No paragraph analyzed yet.";
    textBitsBox.textContent = "";
    videoStatus.textContent = "No video loaded yet.";
    videoBitsBox.textContent = "";
    resetLogBox.innerHTML = "";
    testOutputBox.textContent = "";
  }

  function buildSimulationCSV(){
    if(!simData){
      return "No simulation data yet. Run a simulation first.";
    }
    const header = [
      "t",
      "ConsciousPerformance",
      "SubconsciousStability",
      "CouplingStrength",
      "ThetaConscious",
      "ThetaSubconscious",
      "zThetaConscious",
      "zThetaSubconscious",
      "EmergenceConscious",
      "EmergenceSubconscious"
    ];
    const lines = [header.join(",")];
    for(let t=0;t<N_TURNS;t++){
      const row = [
        t+1,
        simData.conPerf[t].toFixed(4),
        simData.subStab[t].toFixed(4),
        simData.coupling[t].toFixed(4),
        simData.thetaC[t].toFixed(4),
        simData.thetaS[t].toFixed(4),
        simData.zC[t].toFixed(4),
        simData.zS[t].toFixed(4),
        simData.flagsC[t] ? "YES" : "",
        simData.flagsS[t] ? "YES" : ""
      ];
      lines.push(row.join(","));
    }
    return lines.join("\n");
  }

  /* ---------- REFLEX / AWARENESS TESTS ---------- */
  reflexTestBtn.addEventListener('click', ()=>{
    if(!simData){
      testOutputBox.textContent = "Run any simulation first (baseline or from inputs).";
      return;
    }
    const idx = N_TURNS - 1;
    const s = simData.subStab[idx];
    const thetaS = simData.thetaS[idx];
    let msg;
    if(thetaS < 0.25 || s < 0.3){
      msg = "⛔ Subconscious Engine triggers a survival reset: overload or instability too high. Movement and risk are cut until conditions improve.";
      worldResetCount++;
      resetCountSpan.textContent = worldResetCount;
      appendResetLog(
        "Reset " + worldResetCount +
        ": Subconscious Engine forced a protection stop at turn " + (idx+1) + ". Conscious Captain later says: 'We survived. Adjust the mission.'"
      );
    }else if(thetaS < 0.45 || s < 0.5){
      msg = "⚠️ Subconscious Engine requests caution: reduce load, slow decisions, or restore sleep/light alignment.";
    }else{
      msg = "✅ Subconscious Engine is stable: survival layer says it is safe to continue, but will still monitor for overload.";
    }
    testOutputBox.textContent = msg;
  });

  awarenessTestBtn.addEventListener('click', ()=>{
    if(!simData){
      testOutputBox.textContent = "Run any simulation first (baseline or from inputs).";
      return;
    }
    const idx = N_TURNS - 1;
    const c = simData.conPerf[idx];
    const k = simData.coupling[idx];
    let msg;
    if(c >= 0.6 && k >= 0.7){
      msg = "“I know I exist, I understand what just happened, and I can deliberately adjust my next move.” (Focused Conscious Captain)";
    }else if(c >= 0.4 && k >= 0.5){
      msg = "“I am still here. I nearly slipped, but I can describe the danger and adapt my plan.”";
    }else if(c >= 0.25){
      msg = "“Signal is weak. I know I exist, but I need recovery (sleep, light, or support) before strong decisions.”";
    }else{
      msg = "“Awareness is fading. External support is needed — like a pilot asking ground control for help.”";
    }
    testOutputBox.textContent = msg;
  });

  /* ---------- EVENT LISTENERS ---------- */
  computeEnvBtn.addEventListener('click', computeEnvironment);
  downloadProfileCSVBtn.addEventListener('click', ()=>{
    const csv = buildProfileCSV();
    downloadTextFile("rmk_profile_environment.csv", csv, "text/csv");
  });

  textAnalyzeBtn.addEventListener('click', analyzeTextParagraph);
  textExportBtn.addEventListener('click', ()=>{
    if(!textAnalysis){
      textStatus.textContent = "Nothing to export yet — run the text analysis first.";
      return;
    }
    const csv = buildAnalysisCSV(textAnalysis, "text");
    downloadTextFile("rmk_text_analysis.csv", csv, "text/csv");
  });
  textLoadBtn.addEventListener('click', ()=> textAnalysisFileInput.click());
  textAnalysisFileInput.addEventListener('change', ()=>{
    if(textAnalysisFileInput.files && textAnalysisFileInput.files[0]){
      const file = textAnalysisFileInput.files[0];
      const reader = new FileReader();
      reader.onload = ev=>{
        try{
          const obj = parseAnalysisCSV(ev.target.result);
          textAnalysis = obj;
          const emoLines = EMOTION_NAMES
            .map(k => k + ": " + obj.emotions[k].toFixed(2))
            .join(" · ");
          const bitLine = obj.bits.map((b,i)=>((i+1)+":"+b)).join("  ");
          textStatus.textContent =
            "Loaded text analysis from CSV (dominant: " + (obj.dominant || "unknown") + ").";
          textBitsBox.textContent =
            "Bit-stream (40 turns, from CSV):\n" + bitLine +
            "\n\n27 emotion scores (0–1):\n" + emoLines;
        }catch(e){
          textStatus.textContent = "Could not parse text analysis CSV: " + e.message;
        }
      };
      reader.readAsText(file);
    }
  });
  textClearBtn.addEventListener('click', ()=>{
    textAnalysis = null;
    textStatus.textContent = "Text and text-analysis cleared. You can enter a new paragraph.";
    textBitsBox.textContent = "";
  });

  videoUploadBtn.addEventListener('click', ()=> videoFileInput.click());
  videoFileInput.addEventListener('change', ()=>{
    if(videoFileInput.files && videoFileInput.files[0]){
      analyzeVideoFile(videoFileInput.files[0]);
    }
  });
  videoAnalyzeBtn.addEventListener('click', ()=>{
    if(videoFileInput.files && videoFileInput.files[0]){
      analyzeVideoFile(videoFileInput.files[0]);
    }else if(videoAnalysis){
      videoStatus.textContent = "Video analysis already present (from CSV or last run). You can export or clear.";
    }else{
      videoStatus.textContent = "Please upload a video file first.";
    }
  });
  videoExportBtn.addEventListener('click', ()=>{
    if(!videoAnalysis){
      videoStatus.textContent = "Nothing to export yet — run the video analysis first.";
      return;
    }
    const csv = buildVideoCSV();
    downloadTextFile("rmk_video_analysis.csv", csv, "text/csv");
  });
  videoLoadBtn.addEventListener('click', ()=> videoAnalysisFileInput.click());
  videoAnalysisFileInput.addEventListener('change', ()=>{
    if(videoAnalysisFileInput.files && videoAnalysisFileInput.files[0]){
      const file = videoAnalysisFileInput.files[0];
      const reader = new FileReader();
      reader.onload = ev=>{
        try{
          const obj = parseVideoCSV(ev.target.result);
          videoAnalysis = obj;
          const emoLines = EMOTION_NAMES
            .map(k => k + ": " + obj.emotions[k].toFixed(2))
            .join(" · ");
          const bitLine = obj.bits.map((b,i)=>((i+1)+":"+b)).join("  ");
          videoStatus.textContent =
            "Loaded video analysis from CSV (dominant: " + (obj.dominant || "unknown") +
            ", VoiceArousal=" + obj.voiceArousal.toFixed(2) +
            ", FacialTension=" + obj.facialTension.toFixed(2) + ").";
          videoBitsBox.textContent =
            "Bit-stream (40 turns, from video CSV):\n" + bitLine +
            "\n\n27 emotion scores (0–1):\n" + emoLines;
        }catch(e){
          videoStatus.textContent = "Could not parse video analysis CSV: " + e.message;
        }
      };
      reader.readAsText(file);
    }
  });
  videoClearBtn.addEventListener('click', ()=>{
    videoAnalysis = null;
    videoStatus.textContent = "Video and video-analysis cleared. You can upload a new file.";
    videoBitsBox.textContent = "";
  });

  runFromInputsBtn.addEventListener('click', runSimulationFromInputs);
  runRandomBtn.addEventListener('click', runRandomBaseline);
  resetAllBtn.addEventListener('click', resetAll);
  printBtn.addEventListener('click', ()=> window.print());

  downloadSimCSVBtn.addEventListener('click', ()=>{
    const csv = buildSimulationCSV();
    downloadTextFile("rmk_conscious_subconscious_simulation.csv", csv, "text/csv");
  });
  downloadPNG_Con.addEventListener('click', ()=>{
    downloadCanvasPNG(canvasCon, "rmk_theta_conscious.png");
  });
  downloadPNG_Sub.addEventListener('click', ()=>{
    downloadCanvasPNG(canvasSub, "rmk_theta_subconscious.png");
  });

  // Initial random baseline so the page isn't empty
  runRandomBaseline();
})();
</script>
</body>
</html>
